{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Autoencoder with Annoy for CBIR\n",
    "\n",
    "## Grayscale 32x64 pixels, 4x8x128 encoder convolutions, GlobalAverage to 128 dimensions\n",
    "\n",
    "#### Results: Grayscale, even at this resolution seems MUCH better than Black and White (pure through resize or not) or Edge Detection. Unexpected.  But MUCH better at grouping pills through rotations to one another. \n",
    "\n",
    "\n",
    "From Annoy:\\ - see below:\n",
    "Number of incorrect pills:       0 out of 24 pills\n",
    "Number of incorrect pill images: 0 out of 96 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15081321793875527189\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.list_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "#K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#target_image_size = (64,112)\n",
    "target_image_size = (32,64)\n",
    "\n",
    "color_mode='grayscale' # 'grayscale' or 'rgb'\n",
    "\n",
    "if color_mode=='grayscale':\n",
    "    target_image_size_3D = (target_image_size[0], target_image_size[1], 1)\n",
    "else: #then rgb\n",
    "    target_image_size_3D = (target_image_size[0], target_image_size[1], 3)\n",
    "\n",
    "batch_size_training = 32\n",
    "batch_size_validation = 32\n",
    "\n",
    "# Directories\n",
    "image_dir_base = 'data_with_rotations'\n",
    "image_dir_training = image_dir_base + '/train'\n",
    "image_dir_validation = image_dir_base + '/validate'\n",
    "image_dir_testing = image_dir_base + '/test'\n",
    "image_dir_samples = image_dir_testing\n",
    "\n",
    "# Training variables\n",
    "training_steps_per_epoch = 200\n",
    "training_number_of_epoch = 100\n",
    "validation_steps = 200\n",
    "training_early_stop_patience = 5\n",
    "\n",
    "# Model name to save\n",
    "model_name='autoencoder_v1.0_36x64-4x8x128'\n",
    "\n",
    "# Model name to load for Testing\n",
    "model_name_pretrained = model_name\n",
    "\n",
    "# Encoder model name\n",
    "model_name_encoder = model_name + '-encoder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required items for training\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Dense, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras import callbacks\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately, matplotlib, cv2, etc only print in greyscale \n",
    "#   when you have 3 color axes (RGB) all set to make the image look grey.\n",
    "#   But Keras loads greyscale images with only a single number (to optimize training, etc)\n",
    "#   So, we need to convert any Keras greyscale images to have 3 values\n",
    "\n",
    "def display_image(single_image):\n",
    "    #check to see if image is rgb\n",
    "    if (np.shape(single_image)[-1]==3):\n",
    "        plt.imshow(single_image)\n",
    "    if (np.shape(single_image)[-1]==1):\n",
    "        si = np.concatenate((single_image,single_image,single_image), axis=2)\n",
    "        plt.imshow(si)\n",
    "        \n",
    "def get_image(single_image):\n",
    "    #check to see if image is rgb\n",
    "    if (np.shape(single_image)[-1]==3):\n",
    "        return single_image\n",
    "    if (np.shape(single_image)[-1]==1):\n",
    "        si = np.concatenate((single_image,single_image,single_image), axis=2)\n",
    "        return si\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageDataGenerators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 722 images belonging to 1 classes.\n",
      "Found 191 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Created the Train and Validation image generators\n",
    "\n",
    "# Load the data (in that case MNIST)\n",
    "train_datagen = ImageDataGenerator(\n",
    "        #shear_range=0.05,\n",
    "        #zoom_range=0.01,\n",
    "        #rotation_range=5.00,\n",
    "        #height_shift_range=0.10,\n",
    "        #width_shift_range=0.10,\n",
    "        rescale=1. / 255,\n",
    "        horizontal_flip=False)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        image_dir_training,\n",
    "        target_size=target_image_size,\n",
    "        batch_size=batch_size_training,\n",
    "        class_mode='input',\n",
    "        color_mode=color_mode)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        image_dir_validation,\n",
    "        target_size=target_image_size,\n",
    "        batch_size=batch_size_validation,\n",
    "        class_mode='input',\n",
    "        color_mode=color_mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an Sample image generator and get sample images to use throughout all the training for visualization\n",
    "\n",
    "\n",
    "# Create callback function to use later.\n",
    "sample_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "sample_generator = sample_datagen.flow_from_directory(\n",
    "        image_dir_samples,\n",
    "        target_size=target_image_size,\n",
    "        batch_size=16,\n",
    "        class_mode='input',\n",
    "        color_mode=color_mode)\n",
    "\n",
    "next_batch = next(sample_generator)\n",
    "sample_images = next_batch[0]\n",
    "test_image=sample_images[1]\n",
    "ti = test_image\n",
    "\n",
    "#\n",
    "display_image(test_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model for Training - Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    \n",
    "    \n",
    "    #Input\n",
    "    input_img = Input(shape=target_image_size_3D, name='input')  # adapt this if using `channels_first` image data format\n",
    "    \n",
    "     # Layer 10\n",
    "    x = Conv2D(16, (5, 5), activation='relu', padding='same', strides=(2,2))(input_img)\n",
    "#    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    # Layer 20\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', strides=(2,2))(x)\n",
    "#    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "#    # Added\n",
    "#    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "#    \n",
    "#    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # Layer 30\n",
    "\n",
    "#    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    # Layer 40\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same', name='encoder')(x)\n",
    "\n",
    "    # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "    # Uplayer 40\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    \n",
    "    # Uplayer 30\n",
    "#    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#    x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "#    #Added\n",
    "#    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#    x = UpSampling2D((2, 2))(x)  \n",
    "#    \n",
    "#    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "#    #x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "#    x = UpSampling2D((2, 2))(x)  \n",
    "    \n",
    "    # Uplayer 20\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    \n",
    "    # Uplayer 10\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    \n",
    "    # Output\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='decoded')(x)\n",
    "\n",
    "\n",
    "    autoencoder = Model(input_img, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "    print(autoencoder.outputs)\n",
    "        \n",
    "    return autoencoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback to write sample images to disk\n",
    "class ProgressCallback(callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, sample_image):\n",
    "        self.sample_image = sample_image\n",
    "        self.image4d = self.sample_image[None,:] # predict needs a batch of images (shape=4). This adds a dimension  \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        processed_images = self.model.predict(x=[self.image4d],batch_size=1)\n",
    "         \n",
    "        # plot the image and save it\n",
    "        f = plt.figure()\n",
    "        f.add_subplot(1, 2, 1)  # this line outputs images side-by-side\n",
    "        sim = get_image(self.sample_image)\n",
    "        plt.imshow(sim)\n",
    "        f.add_subplot(1, 2, 2)  # this line outputs images side-by-side\n",
    "        pim = get_image(processed_images[0])\n",
    "        plt.imshow(pim)\n",
    "        plt.suptitle('Epoch ' + str(epoch))\n",
    "        filename = 'epoch-' + str(epoch) + '.png'\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "        #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train_model(model_to_train):\n",
    "    progress = ProgressCallback(sample_image=sample_images[0])\n",
    "    early_stop = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=training_early_stop_patience,\n",
    "                              verbose=0, mode='auto')\n",
    "    model_to_train.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=training_steps_per_epoch,\n",
    "        epochs=training_number_of_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False),progress,early_stop])\n",
    "    \n",
    "    model_to_train.save(model_name + '.h5')\n",
    "    \n",
    "    return model_to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'decoded_1/Sigmoid:0' shape=(?, 32, 64, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "x = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 32, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 32, 16)        416       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 16, 32)         4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 16, 128)        36992     \n",
      "_________________________________________________________________\n",
      "encoder (MaxPooling2D)       (None, 4, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 16, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 16, 32)         36896     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 32, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "decoded (Conv2D)             (None, 32, 64, 1)         145       \n",
      "=================================================================\n",
      "Total params: 231,297\n",
      "Trainable params: 231,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'encoder_1/MaxPool:0' shape=(?, 4, 8, 128) dtype=float32>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show encoder output size (before global pooling)\n",
    "e = x.get_layer('encoder')\n",
    "e.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 40/200 [=====>........................] - ETA: 19s - loss: 0.4904"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-3f97ab21a130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-d0de1e3f3a8d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_to_train)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False),progress,early_stop])\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel_to_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder = x\n",
    "autoencoder = train_model(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install jupyter-tensorboard\n",
    "for i in range(3):\n",
    "    pass\n",
    "    #autoencoder = train_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    #autoencoder = train_model(x)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "#import cv2\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model :\n",
      "Model loaded in:  1.6216092109680176\n"
     ]
    }
   ],
   "source": [
    "# Load the model trained above\n",
    "print('Loading model :')\n",
    "t0 = time.time()\n",
    "autoencoder = load_model(model_name_pretrained + '.h5')\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoder').output)\n",
    "t1 = time.time()\n",
    "print('Model loaded in: ', t1-t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convenience methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class all_directory_images_generator:\n",
    "    def __init__(self, sourcedir='data_with_rotations/test', batch_size=16, color_mode='grayscale', target_image_size=(100,100)):\n",
    "        self.batch_size = batch_size\n",
    "        self.sourcedir = sourcedir\n",
    "        self.color_mode = color_mode\n",
    "        self.target_image_size = target_image_size\n",
    "        \n",
    "        self.test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "        self.test_generator = self.test_datagen.flow_from_directory(\n",
    "                sourcedir,\n",
    "                target_size=target_image_size,\n",
    "                batch_size=self.batch_size,\n",
    "                class_mode='input',\n",
    "                color_mode=self.color_mode,\n",
    "                shuffle=False)\n",
    "        \n",
    "        self.n = self.test_generator.n\n",
    "        self.filenames = self.test_generator.filenames   \n",
    "        self.current_batch = 0\n",
    "        self.max_batch = int(self.n / self.batch_size)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        bi = self.test_generator.batch_index\n",
    "        bs = self.test_generator.batch_size\n",
    "        batch_file_names = self.test_generator.filenames[bi*bs:bi*bs+bs]\n",
    "        return (next(self.test_generator), batch_file_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model from the autoencoder, only up to the embedding layer\n",
    "enc_model = Model(autoencoder.input, autoencoder.get_layer('encoder').output)\n",
    "\n",
    "x1 = enc_model.get_layer('encoder').output\n",
    "#x1 = GlobalMaxPooling2D(name='flat')(x1)\n",
    "x1 = GlobalAveragePooling2D(name='flat')(x1)\n",
    "encoder = Model(enc_model.input, x1)\n",
    "\n",
    "# save the model to disk for reuse later\n",
    "encoder.save(model_name_encoder + '.h5')\n",
    "encoder.save('encoder-32x64-4x8x128-AvgPool-prod.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8100 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary with all filenames (keys) and predicted encodings (values)\n",
    "\n",
    "image_dir_testing = 'data_with_many_rotations/train'\n",
    "#image_dir_testing = 'data_projected/train'\n",
    "\n",
    "\n",
    "image_encoding_dict = {}\n",
    "\n",
    "test_images = all_directory_images_generator(batch_size=45, target_image_size=target_image_size, sourcedir=image_dir_testing)\n",
    "bs = test_images.batch_size\n",
    "\n",
    "for i in range(test_images.max_batch):\n",
    "    images_both_x_and_y, names = next(test_images)\n",
    "    images = images_both_x_and_y[0]\n",
    "    encodings = encoder.predict(images,batch_size=bs)\n",
    "    for j in range(bs):\n",
    "        image_encoding_dict[names[j]]=encodings[j]\n",
    "        \n",
    "\n",
    "\n",
    "# Create dictionary with index integers (keys) and filenames (values)\n",
    "#   This is needed later for Annoy, since it uses integers as item keys, and we have to map back to a filename\n",
    "image_filename_dict = {}\n",
    "\n",
    "i = 0\n",
    "for key, value in image_encoding_dict.items():\n",
    "    image_filename_dict[i]=key\n",
    "    i = i+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/100_0.jpg\n"
     ]
    }
   ],
   "source": [
    "# Let's just view a few input images and output images from the autoencoder\n",
    "#   This includes the decoder part of the autoencoder, so we'll still see an image\n",
    "\n",
    "next_batch, next_filenames = next(test_images) # Use the test_images defined above\n",
    "#next_batch = next(test_generator)\n",
    "images = next_batch[0]\n",
    "first_image=images[0]\n",
    "second_image=images[1]\n",
    "\n",
    "plt.imshow(get_image(first_image))\n",
    "plt.show()\n",
    "\n",
    "#plt.imshow(second_image)\n",
    "#plt.show()\n",
    "\n",
    "recreated_pill = autoencoder.predict(x=images,batch_size=32)\n",
    "\n",
    "plt.imshow(get_image(recreated_pill[0]))\n",
    "plt.show()\n",
    "print(next_filenames[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a feel for the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataframe from the dictionary\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(image_encoding_dict, orient='index')\n",
    "\n",
    "#df['filename'] = df.index\n",
    "#df['image']= df['filename'].apply(lambda x: x.split('/')[-1])\n",
    "#HOLY COW!  All of these are so close together. :-(  Can't differentiate one from another easily - Deeper network help?\n",
    "#df.to_csv('96_images_32x64_AvgPool_4x8.csv')\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.115922</td>\n",
       "      <td>0.191847</td>\n",
       "      <td>0.270207</td>\n",
       "      <td>0.054096</td>\n",
       "      <td>0.068204</td>\n",
       "      <td>0.157335</td>\n",
       "      <td>0.025415</td>\n",
       "      <td>0.192004</td>\n",
       "      <td>0.220203</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046102</td>\n",
       "      <td>0.082868</td>\n",
       "      <td>0.035745</td>\n",
       "      <td>0.099770</td>\n",
       "      <td>0.125680</td>\n",
       "      <td>0.253716</td>\n",
       "      <td>0.084940</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.111233</td>\n",
       "      <td>0.174449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.036587</td>\n",
       "      <td>0.030267</td>\n",
       "      <td>0.049827</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>0.015743</td>\n",
       "      <td>0.049639</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.019910</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017230</td>\n",
       "      <td>0.031542</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>0.043616</td>\n",
       "      <td>0.050452</td>\n",
       "      <td>0.037135</td>\n",
       "      <td>0.041245</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.077971</td>\n",
       "      <td>0.056216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.081537</td>\n",
       "      <td>0.133343</td>\n",
       "      <td>0.032144</td>\n",
       "      <td>0.024470</td>\n",
       "      <td>0.086966</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>0.126799</td>\n",
       "      <td>0.166833</td>\n",
       "      <td>0.016504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007235</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.033599</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.181758</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014794</td>\n",
       "      <td>0.011812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.089897</td>\n",
       "      <td>0.181967</td>\n",
       "      <td>0.224222</td>\n",
       "      <td>0.044909</td>\n",
       "      <td>0.055671</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.175038</td>\n",
       "      <td>0.204565</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037010</td>\n",
       "      <td>0.066005</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>0.058875</td>\n",
       "      <td>0.092813</td>\n",
       "      <td>0.226601</td>\n",
       "      <td>0.058008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042835</td>\n",
       "      <td>0.152807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.109632</td>\n",
       "      <td>0.197850</td>\n",
       "      <td>0.288917</td>\n",
       "      <td>0.057099</td>\n",
       "      <td>0.068567</td>\n",
       "      <td>0.139813</td>\n",
       "      <td>0.021403</td>\n",
       "      <td>0.189117</td>\n",
       "      <td>0.218097</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049002</td>\n",
       "      <td>0.087175</td>\n",
       "      <td>0.031126</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.145332</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>0.073153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077166</td>\n",
       "      <td>0.186890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.145472</td>\n",
       "      <td>0.212518</td>\n",
       "      <td>0.309570</td>\n",
       "      <td>0.061804</td>\n",
       "      <td>0.079196</td>\n",
       "      <td>0.194168</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>0.215083</td>\n",
       "      <td>0.236437</td>\n",
       "      <td>0.042717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059397</td>\n",
       "      <td>0.106437</td>\n",
       "      <td>0.046712</td>\n",
       "      <td>0.133684</td>\n",
       "      <td>0.162902</td>\n",
       "      <td>0.277467</td>\n",
       "      <td>0.100587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190406</td>\n",
       "      <td>0.212091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.200139</td>\n",
       "      <td>0.240417</td>\n",
       "      <td>0.343479</td>\n",
       "      <td>0.073879</td>\n",
       "      <td>0.110064</td>\n",
       "      <td>0.297648</td>\n",
       "      <td>0.065481</td>\n",
       "      <td>0.246342</td>\n",
       "      <td>0.263306</td>\n",
       "      <td>0.071408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080652</td>\n",
       "      <td>0.141092</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.206332</td>\n",
       "      <td>0.203005</td>\n",
       "      <td>0.360413</td>\n",
       "      <td>0.194181</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.271305</td>\n",
       "      <td>0.266455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5    \\\n",
       "count  180.000000  180.000000  180.000000  180.000000  180.000000  180.000000   \n",
       "mean     0.115922    0.191847    0.270207    0.054096    0.068204    0.157335   \n",
       "std      0.036587    0.030267    0.049827    0.010149    0.015743    0.049639   \n",
       "min      0.027028    0.081537    0.133343    0.032144    0.024470    0.086966   \n",
       "25%      0.089897    0.181967    0.224222    0.044909    0.055671    0.122873   \n",
       "50%      0.109632    0.197850    0.288917    0.057099    0.068567    0.139813   \n",
       "75%      0.145472    0.212518    0.309570    0.061804    0.079196    0.194168   \n",
       "max      0.200139    0.240417    0.343479    0.073879    0.110064    0.297648   \n",
       "\n",
       "              6           7           8           9       ...             118  \\\n",
       "count  180.000000  180.000000  180.000000  180.000000     ...      180.000000   \n",
       "mean     0.025415    0.192004    0.220203    0.034969     ...        0.046102   \n",
       "std      0.012557    0.026560    0.019910    0.012018     ...        0.017230   \n",
       "min      0.011019    0.126799    0.166833    0.016504     ...        0.007235   \n",
       "25%      0.017561    0.175038    0.204565    0.025744     ...        0.037010   \n",
       "50%      0.021403    0.189117    0.218097    0.031579     ...        0.049002   \n",
       "75%      0.025693    0.215083    0.236437    0.042717     ...        0.059397   \n",
       "max      0.065481    0.246342    0.263306    0.071408     ...        0.080652   \n",
       "\n",
       "              119         120         121         122         123         124  \\\n",
       "count  180.000000  180.000000  180.000000  180.000000  180.000000  180.000000   \n",
       "mean     0.082868    0.035745    0.099770    0.125680    0.253716    0.084940   \n",
       "std      0.031542    0.015773    0.043616    0.050452    0.037135    0.041245   \n",
       "min      0.010326    0.009269    0.033599    0.008120    0.181758    0.021216   \n",
       "25%      0.066005    0.022638    0.058875    0.092813    0.226601    0.058008   \n",
       "50%      0.087175    0.031126    0.094167    0.145332    0.248200    0.073153   \n",
       "75%      0.106437    0.046712    0.133684    0.162902    0.277467    0.100587   \n",
       "max      0.141092    0.078064    0.206332    0.203005    0.360413    0.194181   \n",
       "\n",
       "              125         126         127  \n",
       "count  180.000000  180.000000  180.000000  \n",
       "mean     0.000176    0.111233    0.174449  \n",
       "std      0.000431    0.077971    0.056216  \n",
       "min      0.000000    0.014794    0.011812  \n",
       "25%      0.000000    0.042835    0.152807  \n",
       "50%      0.000000    0.077166    0.186890  \n",
       "75%      0.000000    0.190406    0.212091  \n",
       "max      0.002525    0.271305    0.266455  \n",
       "\n",
       "[8 rows x 128 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the simple statistics around the encodings\n",
    "dfstat = df.describe()\n",
    "dfstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[158  86 166  68 140 103 163  74 107 137  88  45 173  27  67   9  58 124\n",
      "  43  37 147 108  13   6 130  16 117 178 159  30  20  96  44  64  23  87\n",
      " 104  81   5  17  89  18  69 161   8  42 105 125  71 143 102 168  46  26\n",
      " 113 132  15 106  31 144 134  66  95 146 149 115 111  94 114  47   4  78\n",
      "  12  55  38 110  80 116  53  21 136 150  63 145 138  60  29  59 174   1\n",
      " 122 120  72 170   3  92  51  39 151  91  40 135  83 121 167  28  56  48\n",
      " 129  19 165  11 156 179 155  77 176 123  82  70   0 131  61 172  65 127\n",
      " 157  98 154 100  76  49  22 160 141  24  57 153  14 128  35  41 101   7\n",
      " 118  85 164 148  25  50  62 175  79  73 109 119  33  97 142 171 162  84\n",
      "  54  99  36 177  34 112  32  90  75   2 169 152  10 139 133  52  93 126]\n"
     ]
    }
   ],
   "source": [
    "# See how they all cluster\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "number_of_clusters=180\n",
    "km = KMeans(n_clusters=number_of_clusters)\n",
    "# Normally people fit the matrix\n",
    "km.fit(df)\n",
    "print(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ignore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ignore\n",
       "category        \n",
       "0              1\n",
       "1              1\n",
       "2              1\n",
       "3              1\n",
       "4              1\n",
       "5              1\n",
       "6              1\n",
       "7              1\n",
       "8              1\n",
       "9              1\n",
       "10             1\n",
       "11             1\n",
       "12             1\n",
       "13             1\n",
       "14             1\n",
       "15             1\n",
       "16             1\n",
       "17             1\n",
       "18             1\n",
       "19             1\n",
       "20             1\n",
       "21             1\n",
       "22             1\n",
       "23             1\n",
       "24             1\n",
       "25             1\n",
       "26             1\n",
       "27             1\n",
       "28             1\n",
       "29             1\n",
       "...          ...\n",
       "150            1\n",
       "151            1\n",
       "152            1\n",
       "153            1\n",
       "154            1\n",
       "155            1\n",
       "156            1\n",
       "157            1\n",
       "158            1\n",
       "159            1\n",
       "160            1\n",
       "161            1\n",
       "162            1\n",
       "163            1\n",
       "164            1\n",
       "165            1\n",
       "166            1\n",
       "167            1\n",
       "168            1\n",
       "169            1\n",
       "170            1\n",
       "171            1\n",
       "172            1\n",
       "173            1\n",
       "174            1\n",
       "175            1\n",
       "176            1\n",
       "177            1\n",
       "178            1\n",
       "179            1\n",
       "\n",
       "[180 rows x 1 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to a dataframe - note that to get the index / filename, I had to include the first column\n",
    "results = pd.DataFrame({\n",
    "    'ignore': df[0],\n",
    "    'category': km.labels_\n",
    "})\n",
    "results.groupby('category').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the distance between images\n",
    "#  should be small distances between rotated images - ideally zero\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "distdf = pd.DataFrame(squareform(pdist(df.iloc[:, 1:])), columns = df.index.unique(), index=df.index.unique()) #, columns=df['image'].unique(), index=df['image'].unique())\n",
    "#distdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the covariance between the columns - not useful since it's unscaled. :-(\n",
    "#covdf = df.cov()*10000 #, columns = df.index.unique(), index=df.index.unique()) #, columns=df['image'].unique(), index=df['image'].unique())\n",
    "#covdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the correlation between the columns (which represent a global pool from the encoder convolutions)\n",
    "#   Correlation appears high, likely could do some PCA, but seems like tuning the autoencoder should be able to do that\n",
    "corrdf = df.corr() #, columns = df.index.unique(), index=df.index.unique()) #, columns=df['image'].unique(), index=df['image'].unique())\n",
    "#corrdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annoy for nearest neighbor search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Annoy database file\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "embedding_vector_size = 128\n",
    "\n",
    "f = embedding_vector_size      # Length of item vector that will be indexed\n",
    "t = AnnoyIndex(f)  \n",
    "\n",
    "for i in range(len(image_encoding_dict)):\n",
    "    t.add_item(i,image_encoding_dict[image_filename_dict[i]])\n",
    "    \n",
    "t.build(25) # 25 trees - need to explore what is a good setting here\n",
    "t.save(model_name + '.ann') # Save the model\n",
    "t.save('encoder-32x64-4x8x128-AvgPool-prod_train_images_only.ann')\n",
    "\n",
    "import pickle\n",
    "f = open('encoder-32x64-4x8x128-AvgPool-prod_image_filename_dict.pkl',\"wb\")\n",
    "pickle.dump(image_filename_dict,f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - images/1.jpg : 0.0\n",
      "137 - images/60.jpg : 0.0558062344789505\n",
      "116 - images/41.jpg : 0.05672929808497429\n",
      "89 - images/18.jpg : 0.05809778347611427\n",
      "165 - images/86.jpg : 0.05827219411730766\n"
     ]
    }
   ],
   "source": [
    "# Open Annoy database file get example\n",
    "\n",
    "sample_item_index = 0\n",
    "nn_count = 5 # count of nearest neighbors to find\n",
    "\n",
    "u = AnnoyIndex(f)\n",
    "u.load(model_name + '.ann') # super fast, will just mmap the file\n",
    "\n",
    "nn = u.get_nns_by_item(sample_item_index, nn_count) # will find the 5 nearest neighbors\n",
    "\n",
    "for i in nn:\n",
    "    distance = u.get_distance(sample_item_index, i)\n",
    "    print(str(i) + ' - ' + image_filename_dict[i] + ' : ' + str(distance))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pills with any errors:  0 out of 180.0 pills\n",
      "Number of pill image errors:      0 out of 180 images\n",
      "Number of pills with errors in 1:       0 out of 180.0 pills\n",
      "Number of pill image errors in top 1:   0 out of 180 images\n"
     ]
    }
   ],
   "source": [
    "# Calculate some metric of goodness. Basically, see how many pills clump when rotated. \n",
    "#   In other words, the 4 closest pills to pill 219 should be itself plus the three rotations of it.\n",
    "\n",
    "number_rotations = 1 # the total images for each pill\n",
    "top_n = 1 # only get the top n images for comparison - not looking for 100% perfection, just in top n results\n",
    "\n",
    "same_images={key: [key+i for i in range(number_rotations)] for key in image_filename_dict if key % number_rotations == 0}\n",
    "same_images # key is first value, value is list with all the similar images\n",
    "\n",
    "incorrect_pills = 0 #sum of count of pills\n",
    "incorrect_pill_images = 0 # sum of ALL the mistakes\n",
    "\n",
    "incorrect_pills_top_n = 0\n",
    "incorrect_pill_images_top_n = 0\n",
    "\n",
    "total_pills = len(image_filename_dict)/number_rotations\n",
    "total_pill_images = len(image_filename_dict)\n",
    "\n",
    "for key, value in same_images.items():\n",
    "    top_matches = u.get_nns_by_item(key, number_rotations)\n",
    "    mismatches = set(value)-set(top_matches)\n",
    "    if len(mismatches) != 0:\n",
    "        incorrect_pills += 1\n",
    "        incorrect_pill_images += len(mismatches)\n",
    "    \n",
    "    top_n_mismatches = set(top_matches[0:top_n])-set(value)\n",
    "    if len(top_n_mismatches) != 0:\n",
    "        incorrect_pills_top_n += 1\n",
    "        incorrect_pill_images_top_n += len(top_n_mismatches)  \n",
    "        \n",
    "        #print(image_filename_dict[top_n_mismatches.pop()])\n",
    "        #print(f'Image to match is {image_filename_dict[value[0]]}')\n",
    "        for i in top_matches:\n",
    "            print(image_filename_dict[i])\n",
    "        \n",
    "\n",
    "print(f'Number of pills with any errors:  {incorrect_pills} out of {total_pills} pills')\n",
    "print(f\"Number of pill image errors:      {incorrect_pill_images} out of {total_pill_images} images\")\n",
    "\n",
    "print(f'Number of pills with errors in {top_n}:       {incorrect_pills_top_n} out of {total_pills} pills')\n",
    "print(f\"Number of pill image errors in top {top_n}:   {incorrect_pill_images_top_n} out of {total_pill_images} images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate rotations with Annoy db with only unrotated values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - images/1.jpg : 0.0\n",
      "137 - images/60.jpg : 0.0558062344789505\n",
      "116 - images/41.jpg : 0.05672929808497429\n",
      "89 - images/18.jpg : 0.05809778347611427\n",
      "165 - images/86.jpg : 0.05827219411730766\n"
     ]
    }
   ],
   "source": [
    "# Open Annoy database file to get database\n",
    "\n",
    "sample_item_index = 0\n",
    "nn_count = 5 # count of nearest neighbors to find\n",
    "\n",
    "u = AnnoyIndex(f)\n",
    "\n",
    "# Load the right encoder - hard coded right now\n",
    "u.load('encoder-32x64-4x8x128-AvgPool-prod_train_images_only.ann')\n",
    "\n",
    "\n",
    "nn = u.get_nns_by_item(sample_item_index, nn_count) # will find the 5 nearest neighbors\n",
    "\n",
    "for i in nn:\n",
    "    distance = u.get_distance(sample_item_index, i)\n",
    "    print(str(i) + ' - ' + image_filename_dict[i] + ' : ' + str(distance))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100\n",
      "8100\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "# Go up and run the encoder to get the needed dictionaries for all the rotated images. Will need to rerun stuff.\n",
    "\n",
    "print(len(image_encoding_dict))\n",
    "print(len(image_filename_dict))\n",
    "\n",
    "\n",
    "import pickle\n",
    "f = open('encoder-32x64-4x8x128-AvgPool-prod_image_filename_dict.pkl',\"rb\")\n",
    "annoy_image_encoding_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "print(len(annoy_image_encoding_dict))\n",
    "\n",
    "matches = {}\n",
    "\n",
    "# iterate through image_encoding_dict and find the nearest vector in the \n",
    "for key, encoding in image_encoding_dict.items():\n",
    "    #print(encoding)\n",
    "    closest_in_annoy = u.get_nns_by_vector(encoding, 1)\n",
    "    test_img_name = key\n",
    "    closest_annoy_img_name = annoy_image_encoding_dict[closest_in_annoy[0]]\n",
    "    matches[test_img_name] = closest_annoy_img_name\n",
    "    #print(f'{test_img_name} is closest to {closest_annoy_img_name}')\n",
    "\n",
    "#matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_image_path</th>\n",
       "      <th>input_image_path</th>\n",
       "      <th>predicted_image</th>\n",
       "      <th>input_image</th>\n",
       "      <th>input_image_base</th>\n",
       "      <th>input_image_rotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>images/128.jpg</td>\n",
       "      <td>images/160_238.jpg</td>\n",
       "      <td>128</td>\n",
       "      <td>160_238</td>\n",
       "      <td>160</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>images/108.jpg</td>\n",
       "      <td>images/169_210.jpg</td>\n",
       "      <td>108</td>\n",
       "      <td>169_210</td>\n",
       "      <td>169</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>images/108.jpg</td>\n",
       "      <td>images/169_212.jpg</td>\n",
       "      <td>108</td>\n",
       "      <td>169_212</td>\n",
       "      <td>169</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>images/145.jpg</td>\n",
       "      <td>images/18_284.jpg</td>\n",
       "      <td>145</td>\n",
       "      <td>18_284</td>\n",
       "      <td>18</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>images/145.jpg</td>\n",
       "      <td>images/18_36.jpg</td>\n",
       "      <td>145</td>\n",
       "      <td>18_36</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>images/38.jpg</td>\n",
       "      <td>images/37_116.jpg</td>\n",
       "      <td>38</td>\n",
       "      <td>37_116</td>\n",
       "      <td>37</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>images/38.jpg</td>\n",
       "      <td>images/37_117.jpg</td>\n",
       "      <td>38</td>\n",
       "      <td>37_117</td>\n",
       "      <td>37</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>images/38.jpg</td>\n",
       "      <td>images/37_120.jpg</td>\n",
       "      <td>38</td>\n",
       "      <td>37_120</td>\n",
       "      <td>37</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_104.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_104</td>\n",
       "      <td>38</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_119.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_119</td>\n",
       "      <td>38</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_124.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_124</td>\n",
       "      <td>38</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_126.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_126</td>\n",
       "      <td>38</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_151.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_151</td>\n",
       "      <td>38</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_168.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_168</td>\n",
       "      <td>38</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_169.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_169</td>\n",
       "      <td>38</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_173.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_173</td>\n",
       "      <td>38</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_193.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_193</td>\n",
       "      <td>38</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_194.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_194</td>\n",
       "      <td>38</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_198.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_198</td>\n",
       "      <td>38</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_257.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_257</td>\n",
       "      <td>38</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_260.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_260</td>\n",
       "      <td>38</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_277.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_277</td>\n",
       "      <td>38</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_288.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_288</td>\n",
       "      <td>38</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_30.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_30</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_323.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_323</td>\n",
       "      <td>38</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5023</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_326.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_326</td>\n",
       "      <td>38</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5024</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_328.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_328</td>\n",
       "      <td>38</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_35.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_35</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_36.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_36</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_37.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_37</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_79.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_79</td>\n",
       "      <td>38</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>images/37.jpg</td>\n",
       "      <td>images/38_96.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>38_96</td>\n",
       "      <td>38</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6578</th>\n",
       "      <td>images/157.jpg</td>\n",
       "      <td>images/6_153.jpg</td>\n",
       "      <td>157</td>\n",
       "      <td>6_153</td>\n",
       "      <td>6</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6584</th>\n",
       "      <td>images/157.jpg</td>\n",
       "      <td>images/6_192.jpg</td>\n",
       "      <td>157</td>\n",
       "      <td>6_192</td>\n",
       "      <td>6</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>images/157.jpg</td>\n",
       "      <td>images/6_198.jpg</td>\n",
       "      <td>157</td>\n",
       "      <td>6_198</td>\n",
       "      <td>6</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6590</th>\n",
       "      <td>images/157.jpg</td>\n",
       "      <td>images/6_217.jpg</td>\n",
       "      <td>157</td>\n",
       "      <td>6_217</td>\n",
       "      <td>6</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6608</th>\n",
       "      <td>images/157.jpg</td>\n",
       "      <td>images/6_62.jpg</td>\n",
       "      <td>157</td>\n",
       "      <td>6_62</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>images/112.jpg</td>\n",
       "      <td>images/78_241.jpg</td>\n",
       "      <td>112</td>\n",
       "      <td>78_241</td>\n",
       "      <td>78</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7546</th>\n",
       "      <td>images/94.jpg</td>\n",
       "      <td>images/89_281.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>89_281</td>\n",
       "      <td>89</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>images/94.jpg</td>\n",
       "      <td>images/92_119.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>92_119</td>\n",
       "      <td>92</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>images/94.jpg</td>\n",
       "      <td>images/92_120.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>92_120</td>\n",
       "      <td>92</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7699</th>\n",
       "      <td>images/94.jpg</td>\n",
       "      <td>images/92_121.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>92_121</td>\n",
       "      <td>92</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>images/94.jpg</td>\n",
       "      <td>images/92_192.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>92_192</td>\n",
       "      <td>92</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>images/94.jpg</td>\n",
       "      <td>images/92_206.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>92_206</td>\n",
       "      <td>92</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>images/94.jpg</td>\n",
       "      <td>images/92_299.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>92_299</td>\n",
       "      <td>92</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7727</th>\n",
       "      <td>images/94.jpg</td>\n",
       "      <td>images/92_301.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>92_301</td>\n",
       "      <td>92</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7729</th>\n",
       "      <td>images/94.jpg</td>\n",
       "      <td>images/92_340.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>92_340</td>\n",
       "      <td>92</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730</th>\n",
       "      <td>images/94.jpg</td>\n",
       "      <td>images/92_343.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>92_343</td>\n",
       "      <td>92</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted_image_path    input_image_path predicted_image input_image  \\\n",
       "2994       images/128.jpg  images/160_238.jpg             128     160_238   \n",
       "3388       images/108.jpg  images/169_210.jpg             108     169_210   \n",
       "3389       images/108.jpg  images/169_212.jpg             108     169_212   \n",
       "4024       images/145.jpg   images/18_284.jpg             145      18_284   \n",
       "4037       images/145.jpg    images/18_36.jpg             145       18_36   \n",
       "4952        images/38.jpg   images/37_116.jpg              38      37_116   \n",
       "4953        images/38.jpg   images/37_117.jpg              38      37_117   \n",
       "4954        images/38.jpg   images/37_120.jpg              38      37_120   \n",
       "4996        images/37.jpg   images/38_104.jpg              37      38_104   \n",
       "4997        images/37.jpg   images/38_119.jpg              37      38_119   \n",
       "4998        images/37.jpg   images/38_124.jpg              37      38_124   \n",
       "4999        images/37.jpg   images/38_126.jpg              37      38_126   \n",
       "5003        images/37.jpg   images/38_151.jpg              37      38_151   \n",
       "5007        images/37.jpg   images/38_168.jpg              37      38_168   \n",
       "5008        images/37.jpg   images/38_169.jpg              37      38_169   \n",
       "5009        images/37.jpg   images/38_173.jpg              37      38_173   \n",
       "5011        images/37.jpg   images/38_193.jpg              37      38_193   \n",
       "5012        images/37.jpg   images/38_194.jpg              37      38_194   \n",
       "5013        images/37.jpg   images/38_198.jpg              37      38_198   \n",
       "5014        images/37.jpg   images/38_257.jpg              37      38_257   \n",
       "5015        images/37.jpg   images/38_260.jpg              37      38_260   \n",
       "5018        images/37.jpg   images/38_277.jpg              37      38_277   \n",
       "5019        images/37.jpg   images/38_288.jpg              37      38_288   \n",
       "5020        images/37.jpg    images/38_30.jpg              37       38_30   \n",
       "5022        images/37.jpg   images/38_323.jpg              37      38_323   \n",
       "5023        images/37.jpg   images/38_326.jpg              37      38_326   \n",
       "5024        images/37.jpg   images/38_328.jpg              37      38_328   \n",
       "5030        images/37.jpg    images/38_35.jpg              37       38_35   \n",
       "5031        images/37.jpg    images/38_36.jpg              37       38_36   \n",
       "5032        images/37.jpg    images/38_37.jpg              37       38_37   \n",
       "5037        images/37.jpg    images/38_79.jpg              37       38_79   \n",
       "5039        images/37.jpg    images/38_96.jpg              37       38_96   \n",
       "6578       images/157.jpg    images/6_153.jpg             157       6_153   \n",
       "6584       images/157.jpg    images/6_192.jpg             157       6_192   \n",
       "6585       images/157.jpg    images/6_198.jpg             157       6_198   \n",
       "6590       images/157.jpg    images/6_217.jpg             157       6_217   \n",
       "6608       images/157.jpg     images/6_62.jpg             157        6_62   \n",
       "6991       images/112.jpg   images/78_241.jpg             112      78_241   \n",
       "7546        images/94.jpg   images/89_281.jpg              94      89_281   \n",
       "7697        images/94.jpg   images/92_119.jpg              94      92_119   \n",
       "7698        images/94.jpg   images/92_120.jpg              94      92_120   \n",
       "7699        images/94.jpg   images/92_121.jpg              94      92_121   \n",
       "7711        images/94.jpg   images/92_192.jpg              94      92_192   \n",
       "7712        images/94.jpg   images/92_206.jpg              94      92_206   \n",
       "7726        images/94.jpg   images/92_299.jpg              94      92_299   \n",
       "7727        images/94.jpg   images/92_301.jpg              94      92_301   \n",
       "7729        images/94.jpg   images/92_340.jpg              94      92_340   \n",
       "7730        images/94.jpg   images/92_343.jpg              94      92_343   \n",
       "\n",
       "     input_image_base input_image_rotation  \n",
       "2994              160                  238  \n",
       "3388              169                  210  \n",
       "3389              169                  212  \n",
       "4024               18                  284  \n",
       "4037               18                   36  \n",
       "4952               37                  116  \n",
       "4953               37                  117  \n",
       "4954               37                  120  \n",
       "4996               38                  104  \n",
       "4997               38                  119  \n",
       "4998               38                  124  \n",
       "4999               38                  126  \n",
       "5003               38                  151  \n",
       "5007               38                  168  \n",
       "5008               38                  169  \n",
       "5009               38                  173  \n",
       "5011               38                  193  \n",
       "5012               38                  194  \n",
       "5013               38                  198  \n",
       "5014               38                  257  \n",
       "5015               38                  260  \n",
       "5018               38                  277  \n",
       "5019               38                  288  \n",
       "5020               38                   30  \n",
       "5022               38                  323  \n",
       "5023               38                  326  \n",
       "5024               38                  328  \n",
       "5030               38                   35  \n",
       "5031               38                   36  \n",
       "5032               38                   37  \n",
       "5037               38                   79  \n",
       "5039               38                   96  \n",
       "6578                6                  153  \n",
       "6584                6                  192  \n",
       "6585                6                  198  \n",
       "6590                6                  217  \n",
       "6608                6                   62  \n",
       "6991               78                  241  \n",
       "7546               89                  281  \n",
       "7697               92                  119  \n",
       "7698               92                  120  \n",
       "7699               92                  121  \n",
       "7711               92                  192  \n",
       "7712               92                  206  \n",
       "7726               92                  299  \n",
       "7727               92                  301  \n",
       "7729               92                  340  \n",
       "7730               92                  343  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn into pandas dataframe for easier manipulation\n",
    "df = pd.DataFrame.from_dict(matches, orient='index', columns=['predicted_image_path'])\n",
    "df['input_image_path'] = df.index\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)\n",
    "df['predicted_image'] = df['predicted_image_path'].apply(lambda x: x.split('/')[1])\n",
    "df['predicted_image'] = df['predicted_image'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "df['input_image'] = df['input_image_path'].apply(lambda x: x.split('/')[1])\n",
    "df['input_image'] = df['input_image'].apply(lambda x: x.split('.')[0])\n",
    "df['input_image_base'] = df['input_image'].apply(lambda x: x.split('_')[0])\n",
    "df['input_image_rotation'] = df['input_image'].apply(lambda x: x.split('_')[1])\n",
    "\n",
    "\n",
    "errors = df[df['predicted_image'] != df['input_image_base']]\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
