{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the initial take of pulling the MNIST CBIR from https://blog.sicara.com/keras-tutorial-content-based-image-retrieval-convolutional-denoising-autoencoder-dc91450cc511\n",
    "#    and making it work in a Jupyter notebook for unrotated pill images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10958541762828628572\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "#K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_size = (64,112)\n",
    "target_image_size_3D = (64,112,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required items for training\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Dense, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras import callbacks\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# For training\n",
    "# Import needed libraries\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "#import cv2\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(single_image):\n",
    "    #check to see if image is rgb\n",
    "    if (np.shape(single_image)[-1]==3):\n",
    "        plt.imshow(single_image)\n",
    "    if (np.shape(single_image)[-1]==1):\n",
    "        si = np.concatenate((single_image,single_image,single_image), axis=2)\n",
    "        plt.imshow(si)\n",
    "        \n",
    "def get_image(single_image):\n",
    "    #check to see if image is rgb\n",
    "    if (np.shape(single_image)[-1]==3):\n",
    "        return single_image\n",
    "    if (np.shape(single_image)[-1]==1):\n",
    "        si = np.concatenate((single_image,single_image,single_image), axis=2)\n",
    "        return si\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 722 images belonging to 1 classes.\n",
      "Found 191 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the data (in that case MNIST)\n",
    "train_datagen = ImageDataGenerator(\n",
    "        #shear_range=0.05,\n",
    "        #zoom_range=0.01,\n",
    "        #rotation_range=5.00,\n",
    "        #height_shift_range=0.10,\n",
    "        #width_shift_range=0.10,\n",
    "        rescale=1. / 255,\n",
    "        horizontal_flip=False)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data_with_rotations/train',\n",
    "        target_size=target_image_size,\n",
    "        batch_size=16,\n",
    "        class_mode='input',\n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'data_with_rotations/validate',\n",
    "        target_size=target_image_size,\n",
    "        batch_size=32,\n",
    "        class_mode='input',\n",
    "        color_mode='grayscale')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 images belonging to 1 classes.\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get 16 sample images to use throughout all the training for visualization\n",
    "# Load Test images to generate testing data\n",
    "sample_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "sample_generator = sample_datagen.flow_from_directory(\n",
    "        'data_with_rotations/test',\n",
    "        target_size=target_image_size,\n",
    "        batch_size=16,\n",
    "        class_mode='input',\n",
    "        color_mode='grayscale')\n",
    "\n",
    "next_batch = next(sample_generator)\n",
    "sample_images = next_batch[0]\n",
    "test_image=sample_images[1]\n",
    "ti = test_image\n",
    "\n",
    "print(np.shape(ti)[-1])\n",
    "\n",
    "display_image(test_image)\n",
    "\n",
    "#test_display = np.concatenate((ti,ti,ti), axis=2)\n",
    "\n",
    "#plt.imshow(test_display)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 64, 112, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_image[:,:,0])\n",
    "np.shape(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    \n",
    "    big_conv = (7,7)\n",
    "    num_conv = 128\n",
    "    \n",
    "    \n",
    "    #Input\n",
    "    input_img = Input(shape=target_image_size_3D, name='input')  # adapt this if using `channels_first` image data format\n",
    "    \n",
    "     # Layer 10\n",
    "    x = Conv2D(16, (5, 5), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    # Layer 20\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "#    # Added\n",
    "#    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "#    \n",
    "#    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "     # Layer 30\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    # Layer 40\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same', name='encoder')(x)\n",
    "\n",
    "    # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "    # Uplayer 40\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    \n",
    "    # Uplayer 30\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "#    #Added\n",
    "#    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#    x = UpSampling2D((2, 2))(x)  \n",
    "#    \n",
    "#    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "#    #x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "#    x = UpSampling2D((2, 2))(x)  \n",
    "    \n",
    "    # Uplayer 20\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    \n",
    "    # Uplayer 10\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    \n",
    "    # Output\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='decoded')(x)\n",
    "\n",
    "\n",
    "    autoencoder = Model(input_img, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "    print(autoencoder.outputs)\n",
    "        \n",
    "    return autoencoder\n",
    "    \n",
    "    #autoencoder.fit_generator(\n",
    "    #    train_generator,\n",
    "    #    steps_per_epoch=2000,\n",
    "    #    epochs=10,\n",
    "    #    validation_data=validation_generator,\n",
    "    #    validation_steps=800)\n",
    "        #callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])\n",
    "    \n",
    "    # autoencoder.save('autoencoder_pill.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressCallback(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #print('epoch ended')\n",
    "        #print(self.model)\n",
    "        \n",
    "        processed_images = self.model.predict(x=sample_images,batch_size=16)\n",
    "         \n",
    "        \n",
    "        # plot the image\n",
    "        f = plt.figure()\n",
    "        f.add_subplot(1, 2, 1)  # this line outputs images side-by-side\n",
    "        sim = get_image(sample_images[0])\n",
    "        plt.imshow(sim)\n",
    "        f.add_subplot(1, 2, 2)  # this line outputs images side-by-side\n",
    "        pim = get_image(processed_images[0])\n",
    "        plt.imshow(pim)\n",
    "        plt.suptitle('Epoch ' + str(epoch))\n",
    "        filename = 'epoch-' + str(epoch) + '.png'\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model_to_train):\n",
    "    progress = ProgressCallback()\n",
    "    early_stop = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=4,\n",
    "                              verbose=0, mode='auto')\n",
    "    model_to_train.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=200,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=100,\n",
    "        callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False),progress,early_stop])\n",
    "    \n",
    "    model_to_train.save('autoencoder_pill4.h5')\n",
    "    \n",
    "    return model_to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.save('autoencoder_8by14by128.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'decoded/Sigmoid:0' shape=(?, 64, 112, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "x = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 64, 112, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 112, 16)       416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 56, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 14, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 14, 128)        36992     \n",
      "_________________________________________________________________\n",
      "encoder (MaxPooling2D)       (None, 4, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 14, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 14, 32)         36896     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 56, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 64, 112, 16)       0         \n",
      "_________________________________________________________________\n",
      "decoded (Conv2D)             (None, 64, 112, 1)        145       \n",
      "=================================================================\n",
      "Total params: 249,793\n",
      "Trainable params: 249,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'encoder/MaxPool:0' shape=(?, 4, 7, 128) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = x.get_layer('encoder')\n",
    "e.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = ProgressCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.5243 - val_loss: 0.4911\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.5104 - val_loss: 0.4835\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.5023 - val_loss: 0.4752\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.4981 - val_loss: 0.4730\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.4967 - val_loss: 0.4757\n"
     ]
    }
   ],
   "source": [
    "autoencoder = train_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.4964 - val_loss: 0.4731\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.4957 - val_loss: 0.4709\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.4947 - val_loss: 0.4708\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.4945 - val_loss: 0.4697\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 0.4932 - val_loss: 0.4705\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.4931 - val_loss: 0.4687\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 0.4926 - val_loss: 0.4684\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.4923 - val_loss: 0.4697\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 0.4919 - val_loss: 0.4684\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.4922 - val_loss: 0.4680\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 0.4915 - val_loss: 0.4680\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.4914 - val_loss: 0.4690\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.4915 - val_loss: 0.4678\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 0.4913 - val_loss: 0.4677\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.4908 - val_loss: 0.4668\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.4910 - val_loss: 0.4669\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 0.4903 - val_loss: 0.4670\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.4910 - val_loss: 0.4667\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.4906 - val_loss: 0.4662\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.4908 - val_loss: 0.4669\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4903 - val_loss: 0.4660\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.4902 - val_loss: 0.4660\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 0.4902 - val_loss: 0.4660\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 0.4901 - val_loss: 0.4660\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 0.4896 - val_loss: 0.4663\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install jupyter-tensorboard\n",
    "for i in range(5):\n",
    "    autoencoder = train_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4894 - val_loss: 0.4657\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.4901 - val_loss: 0.4671\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.4900 - val_loss: 0.4657\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.4904 - val_loss: 0.4660\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4896 - val_loss: 0.4657\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.4903 - val_loss: 0.4655\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4892 - val_loss: 0.4655\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 0.4895 - val_loss: 0.4654\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4894 - val_loss: 0.4654\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.4897 - val_loss: 0.4657\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4895 - val_loss: 0.4652\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.4894 - val_loss: 0.4653\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 0.4895 - val_loss: 0.4653\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.4892 - val_loss: 0.4652\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4890 - val_loss: 0.4657\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.4895 - val_loss: 0.4655\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.4892 - val_loss: 0.4655\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.4896 - val_loss: 0.4654\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.4894 - val_loss: 0.4651\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.4892 - val_loss: 0.4651\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.4890 - val_loss: 0.4651\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4894 - val_loss: 0.4651\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.4887 - val_loss: 0.4649\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4891 - val_loss: 0.4649\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.4894 - val_loss: 0.4652\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4893 - val_loss: 0.4651\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.4888 - val_loss: 0.4649\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.4889 - val_loss: 0.4655\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4890 - val_loss: 0.4648\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.4887 - val_loss: 0.4650\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4891 - val_loss: 0.4649\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4892 - val_loss: 0.4647\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4888 - val_loss: 0.4647\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.4891 - val_loss: 0.4653\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.4888 - val_loss: 0.4647\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4884 - val_loss: 0.4648\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4892 - val_loss: 0.4648\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4887 - val_loss: 0.4647\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.4888 - val_loss: 0.4647\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.4893 - val_loss: 0.4651\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.4887 - val_loss: 0.4647\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4880 - val_loss: 0.4649\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 0.4889 - val_loss: 0.4645\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.4888 - val_loss: 0.4646\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.4882 - val_loss: 0.4648\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.4891 - val_loss: 0.4646\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.4881 - val_loss: 0.4645\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 0.4886 - val_loss: 0.4644\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 0.4884 - val_loss: 0.4644\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4884 - val_loss: 0.4643\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.4888 - val_loss: 0.4644\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.4884 - val_loss: 0.4643\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4888 - val_loss: 0.4645\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.4882 - val_loss: 0.4644\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.4889 - val_loss: 0.4646\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.4883 - val_loss: 0.4645\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.4883 - val_loss: 0.4643\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.4883 - val_loss: 0.4644\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.4885 - val_loss: 0.4643\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4881 - val_loss: 0.4643\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4884 - val_loss: 0.4643\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4883 - val_loss: 0.4645\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.4887 - val_loss: 0.4645\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4882 - val_loss: 0.4644\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4883 - val_loss: 0.4642\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.4885 - val_loss: 0.4643\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4878 - val_loss: 0.4642\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.4884 - val_loss: 0.4642\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4886 - val_loss: 0.4642\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.4882 - val_loss: 0.4641\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 43s 213ms/step - loss: 0.4881 - val_loss: 0.4643\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4886 - val_loss: 0.4643\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4880 - val_loss: 0.4644\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.4879 - val_loss: 0.4644\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.4882 - val_loss: 0.4641\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.4881 - val_loss: 0.4643\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.4882 - val_loss: 0.4642\n",
      "Epoch 3/5\n",
      "109/200 [===============>..............] - ETA: 18s - loss: 0.4880"
     ]
    }
   ],
   "source": [
    "#!pip3 install jupyter-tensorboard\n",
    "for i in range(25):\n",
    "    autoencoder = train_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "#import cv2\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model :\n",
      "Model loaded in:  2.6054461002349854\n"
     ]
    }
   ],
   "source": [
    "# Load the model trained above\n",
    "print('Loading model :')\n",
    "t0 = time.time()\n",
    "autoencoder = load_model('autoencoder_pill4.h5')\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoder').output)\n",
    "t1 = time.time()\n",
    "print('Model loaded in: ', t1-t0)\n",
    "\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class all_directory_images_generator:\n",
    "    def __init__(self, sourcedir='data_with_rotations/test', batch_size=16):\n",
    "        self.batch_size = batch_size\n",
    "        self.sourcedir = sourcedir\n",
    "        \n",
    "        self.test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "        self.test_generator = self.test_datagen.flow_from_directory(\n",
    "                sourcedir,\n",
    "                target_size=target_image_size,\n",
    "                batch_size=self.batch_size,\n",
    "                class_mode='input',\n",
    "                color_mode='grayscale',\n",
    "                shuffle=False)\n",
    "        \n",
    "        self.n = self.test_generator.n\n",
    "        self.filenames = self.test_generator.filenames\n",
    "        \n",
    "        self.current_batch = 0\n",
    "        self.max_batch = int(self.n / self.batch_size)\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        bi = self.test_generator.batch_index\n",
    "        bs = self.test_generator.batch_size\n",
    "        batch_file_names = self.test_generator.filenames[bi*bs:bi*bs+bs]\n",
    "        return (next(self.test_generator), batch_file_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model from the autoencoder, only up to the embedding layer\n",
    "enc_model = Model(autoencoder.input, autoencoder.get_layer('encoder').output)\n",
    "\n",
    "x1 = enc_model.get_layer('encoder').output\n",
    "x1 = GlobalMaxPooling2D(name='flat')(x1)\n",
    "#x1 = GlobalAveragePooling2D(name='flat')(x1)\n",
    "encoder = Model(enc_model.input, x1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dict = {}\n",
    "\n",
    "\n",
    "test_images = all_directory_images_generator(batch_size=16)\n",
    "bs = test_images.batch_size\n",
    "\n",
    "for i in range(test_images.max_batch):\n",
    "    images_both_x_and_y, names = next(test_images)\n",
    "    images = images_both_x_and_y[0]\n",
    "    encodings = encoder.predict(images,batch_size=bs)\n",
    "    for j in range(bs):\n",
    "        dict[names[j]]=encodings[j]\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>images/229.jpg</th>\n",
       "      <td>0.347885</td>\n",
       "      <td>0.312121</td>\n",
       "      <td>0.426286</td>\n",
       "      <td>0.280628</td>\n",
       "      <td>0.266532</td>\n",
       "      <td>0.417493</td>\n",
       "      <td>0.190636</td>\n",
       "      <td>0.028607</td>\n",
       "      <td>0.386184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633016</td>\n",
       "      <td>0.136140</td>\n",
       "      <td>0.585315</td>\n",
       "      <td>0.321328</td>\n",
       "      <td>0.319590</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.573633</td>\n",
       "      <td>0.325578</td>\n",
       "      <td>0.407397</td>\n",
       "      <td>0.489200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/229_196.jpg</th>\n",
       "      <td>0.348042</td>\n",
       "      <td>0.282433</td>\n",
       "      <td>0.475093</td>\n",
       "      <td>0.278334</td>\n",
       "      <td>0.251386</td>\n",
       "      <td>0.427501</td>\n",
       "      <td>0.168334</td>\n",
       "      <td>0.027984</td>\n",
       "      <td>0.368423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594656</td>\n",
       "      <td>0.143132</td>\n",
       "      <td>0.649892</td>\n",
       "      <td>0.295149</td>\n",
       "      <td>0.357228</td>\n",
       "      <td>0.102963</td>\n",
       "      <td>0.465853</td>\n",
       "      <td>0.345594</td>\n",
       "      <td>0.407546</td>\n",
       "      <td>0.555374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/229_262.jpg</th>\n",
       "      <td>0.347790</td>\n",
       "      <td>0.283312</td>\n",
       "      <td>0.440433</td>\n",
       "      <td>0.263835</td>\n",
       "      <td>0.254680</td>\n",
       "      <td>0.433728</td>\n",
       "      <td>0.165925</td>\n",
       "      <td>0.027647</td>\n",
       "      <td>0.334038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564455</td>\n",
       "      <td>0.082824</td>\n",
       "      <td>0.627839</td>\n",
       "      <td>0.240245</td>\n",
       "      <td>0.350610</td>\n",
       "      <td>0.073178</td>\n",
       "      <td>0.443575</td>\n",
       "      <td>0.345262</td>\n",
       "      <td>0.407321</td>\n",
       "      <td>0.571226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/229_45.jpg</th>\n",
       "      <td>0.348421</td>\n",
       "      <td>0.282668</td>\n",
       "      <td>0.512960</td>\n",
       "      <td>0.261995</td>\n",
       "      <td>0.292136</td>\n",
       "      <td>0.529770</td>\n",
       "      <td>0.146988</td>\n",
       "      <td>0.027779</td>\n",
       "      <td>0.344377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574621</td>\n",
       "      <td>0.125997</td>\n",
       "      <td>0.620627</td>\n",
       "      <td>0.300635</td>\n",
       "      <td>0.352492</td>\n",
       "      <td>0.097335</td>\n",
       "      <td>0.449535</td>\n",
       "      <td>0.352030</td>\n",
       "      <td>0.408274</td>\n",
       "      <td>0.481438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/230.jpg</th>\n",
       "      <td>0.348366</td>\n",
       "      <td>0.238829</td>\n",
       "      <td>0.436449</td>\n",
       "      <td>0.288226</td>\n",
       "      <td>0.140132</td>\n",
       "      <td>0.453725</td>\n",
       "      <td>0.169919</td>\n",
       "      <td>0.027888</td>\n",
       "      <td>0.348023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622958</td>\n",
       "      <td>0.065635</td>\n",
       "      <td>0.623131</td>\n",
       "      <td>0.320368</td>\n",
       "      <td>0.311093</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>0.450236</td>\n",
       "      <td>0.336909</td>\n",
       "      <td>0.408458</td>\n",
       "      <td>0.457011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/230_200.jpg</th>\n",
       "      <td>0.348400</td>\n",
       "      <td>0.251860</td>\n",
       "      <td>0.505937</td>\n",
       "      <td>0.284331</td>\n",
       "      <td>0.142422</td>\n",
       "      <td>0.518545</td>\n",
       "      <td>0.162111</td>\n",
       "      <td>0.027354</td>\n",
       "      <td>0.348718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666371</td>\n",
       "      <td>0.102216</td>\n",
       "      <td>0.597925</td>\n",
       "      <td>0.271064</td>\n",
       "      <td>0.277888</td>\n",
       "      <td>0.107364</td>\n",
       "      <td>0.464044</td>\n",
       "      <td>0.368886</td>\n",
       "      <td>0.409705</td>\n",
       "      <td>0.464650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/230_287.jpg</th>\n",
       "      <td>0.348064</td>\n",
       "      <td>0.219773</td>\n",
       "      <td>0.458193</td>\n",
       "      <td>0.287645</td>\n",
       "      <td>0.133351</td>\n",
       "      <td>0.488429</td>\n",
       "      <td>0.165254</td>\n",
       "      <td>0.027434</td>\n",
       "      <td>0.349248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598150</td>\n",
       "      <td>0.159060</td>\n",
       "      <td>0.622874</td>\n",
       "      <td>0.309921</td>\n",
       "      <td>0.255302</td>\n",
       "      <td>0.144452</td>\n",
       "      <td>0.451410</td>\n",
       "      <td>0.366415</td>\n",
       "      <td>0.407984</td>\n",
       "      <td>0.491362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/230_341.jpg</th>\n",
       "      <td>0.348314</td>\n",
       "      <td>0.247347</td>\n",
       "      <td>0.483573</td>\n",
       "      <td>0.287436</td>\n",
       "      <td>0.141763</td>\n",
       "      <td>0.493413</td>\n",
       "      <td>0.161969</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>0.343228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613823</td>\n",
       "      <td>0.065556</td>\n",
       "      <td>0.647031</td>\n",
       "      <td>0.252956</td>\n",
       "      <td>0.272582</td>\n",
       "      <td>0.097495</td>\n",
       "      <td>0.471553</td>\n",
       "      <td>0.342693</td>\n",
       "      <td>0.408179</td>\n",
       "      <td>0.510708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/231.jpg</th>\n",
       "      <td>0.348331</td>\n",
       "      <td>0.253640</td>\n",
       "      <td>0.535971</td>\n",
       "      <td>0.281920</td>\n",
       "      <td>0.195679</td>\n",
       "      <td>0.519314</td>\n",
       "      <td>0.132833</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.318920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591173</td>\n",
       "      <td>0.067689</td>\n",
       "      <td>0.611022</td>\n",
       "      <td>0.382788</td>\n",
       "      <td>0.274460</td>\n",
       "      <td>0.080491</td>\n",
       "      <td>0.500623</td>\n",
       "      <td>0.340503</td>\n",
       "      <td>0.408043</td>\n",
       "      <td>0.550544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/231_212.jpg</th>\n",
       "      <td>0.349236</td>\n",
       "      <td>0.224221</td>\n",
       "      <td>0.468002</td>\n",
       "      <td>0.285454</td>\n",
       "      <td>0.192864</td>\n",
       "      <td>0.516859</td>\n",
       "      <td>0.129370</td>\n",
       "      <td>0.032095</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583231</td>\n",
       "      <td>0.072134</td>\n",
       "      <td>0.652523</td>\n",
       "      <td>0.309151</td>\n",
       "      <td>0.253360</td>\n",
       "      <td>0.073784</td>\n",
       "      <td>0.399554</td>\n",
       "      <td>0.346561</td>\n",
       "      <td>0.408868</td>\n",
       "      <td>0.545853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/231_56.jpg</th>\n",
       "      <td>0.349252</td>\n",
       "      <td>0.216469</td>\n",
       "      <td>0.462914</td>\n",
       "      <td>0.286893</td>\n",
       "      <td>0.218426</td>\n",
       "      <td>0.514795</td>\n",
       "      <td>0.134831</td>\n",
       "      <td>0.027136</td>\n",
       "      <td>0.352922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611087</td>\n",
       "      <td>0.148659</td>\n",
       "      <td>0.630430</td>\n",
       "      <td>0.328203</td>\n",
       "      <td>0.260759</td>\n",
       "      <td>0.124260</td>\n",
       "      <td>0.409085</td>\n",
       "      <td>0.346472</td>\n",
       "      <td>0.408932</td>\n",
       "      <td>0.645593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/231_80.jpg</th>\n",
       "      <td>0.348276</td>\n",
       "      <td>0.258963</td>\n",
       "      <td>0.483181</td>\n",
       "      <td>0.289719</td>\n",
       "      <td>0.196923</td>\n",
       "      <td>0.541549</td>\n",
       "      <td>0.120920</td>\n",
       "      <td>0.027658</td>\n",
       "      <td>0.336097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613038</td>\n",
       "      <td>0.085445</td>\n",
       "      <td>0.620990</td>\n",
       "      <td>0.310293</td>\n",
       "      <td>0.244655</td>\n",
       "      <td>0.081664</td>\n",
       "      <td>0.426819</td>\n",
       "      <td>0.357750</td>\n",
       "      <td>0.409168</td>\n",
       "      <td>0.557609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/232.jpg</th>\n",
       "      <td>0.348157</td>\n",
       "      <td>0.306357</td>\n",
       "      <td>0.500418</td>\n",
       "      <td>0.253922</td>\n",
       "      <td>0.240013</td>\n",
       "      <td>0.392414</td>\n",
       "      <td>0.158380</td>\n",
       "      <td>0.027359</td>\n",
       "      <td>0.356790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606385</td>\n",
       "      <td>0.091465</td>\n",
       "      <td>0.505573</td>\n",
       "      <td>0.331711</td>\n",
       "      <td>0.343670</td>\n",
       "      <td>0.098643</td>\n",
       "      <td>0.452735</td>\n",
       "      <td>0.341255</td>\n",
       "      <td>0.407176</td>\n",
       "      <td>0.484978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/232_202.jpg</th>\n",
       "      <td>0.348049</td>\n",
       "      <td>0.295973</td>\n",
       "      <td>0.432724</td>\n",
       "      <td>0.265168</td>\n",
       "      <td>0.236663</td>\n",
       "      <td>0.491952</td>\n",
       "      <td>0.142475</td>\n",
       "      <td>0.027718</td>\n",
       "      <td>0.338507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572823</td>\n",
       "      <td>0.059171</td>\n",
       "      <td>0.541217</td>\n",
       "      <td>0.342680</td>\n",
       "      <td>0.356843</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>0.448504</td>\n",
       "      <td>0.343998</td>\n",
       "      <td>0.407555</td>\n",
       "      <td>0.504895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/232_251.jpg</th>\n",
       "      <td>0.348409</td>\n",
       "      <td>0.260203</td>\n",
       "      <td>0.580436</td>\n",
       "      <td>0.262466</td>\n",
       "      <td>0.169528</td>\n",
       "      <td>0.448731</td>\n",
       "      <td>0.144055</td>\n",
       "      <td>0.081140</td>\n",
       "      <td>0.345482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561346</td>\n",
       "      <td>0.092905</td>\n",
       "      <td>0.535058</td>\n",
       "      <td>0.316981</td>\n",
       "      <td>0.286806</td>\n",
       "      <td>0.069862</td>\n",
       "      <td>0.510644</td>\n",
       "      <td>0.328570</td>\n",
       "      <td>0.407334</td>\n",
       "      <td>0.469255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/232_327.jpg</th>\n",
       "      <td>0.348160</td>\n",
       "      <td>0.308511</td>\n",
       "      <td>0.572415</td>\n",
       "      <td>0.252780</td>\n",
       "      <td>0.223937</td>\n",
       "      <td>0.448215</td>\n",
       "      <td>0.144810</td>\n",
       "      <td>0.027983</td>\n",
       "      <td>0.352504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556294</td>\n",
       "      <td>0.096392</td>\n",
       "      <td>0.524904</td>\n",
       "      <td>0.305079</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.072824</td>\n",
       "      <td>0.463550</td>\n",
       "      <td>0.340448</td>\n",
       "      <td>0.407462</td>\n",
       "      <td>0.505545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/233.jpg</th>\n",
       "      <td>0.347988</td>\n",
       "      <td>0.356146</td>\n",
       "      <td>0.458956</td>\n",
       "      <td>0.263893</td>\n",
       "      <td>0.106727</td>\n",
       "      <td>0.361774</td>\n",
       "      <td>0.164111</td>\n",
       "      <td>0.027506</td>\n",
       "      <td>0.338696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450395</td>\n",
       "      <td>0.120138</td>\n",
       "      <td>0.519186</td>\n",
       "      <td>0.240653</td>\n",
       "      <td>0.245660</td>\n",
       "      <td>0.067555</td>\n",
       "      <td>0.393944</td>\n",
       "      <td>0.349942</td>\n",
       "      <td>0.407554</td>\n",
       "      <td>0.539288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/233_207.jpg</th>\n",
       "      <td>0.347542</td>\n",
       "      <td>0.345601</td>\n",
       "      <td>0.456286</td>\n",
       "      <td>0.263432</td>\n",
       "      <td>0.097399</td>\n",
       "      <td>0.349786</td>\n",
       "      <td>0.182256</td>\n",
       "      <td>0.066705</td>\n",
       "      <td>0.344582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454468</td>\n",
       "      <td>0.065276</td>\n",
       "      <td>0.523580</td>\n",
       "      <td>0.249761</td>\n",
       "      <td>0.247186</td>\n",
       "      <td>0.069774</td>\n",
       "      <td>0.521025</td>\n",
       "      <td>0.328173</td>\n",
       "      <td>0.406886</td>\n",
       "      <td>0.551752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/233_337.jpg</th>\n",
       "      <td>0.348107</td>\n",
       "      <td>0.347041</td>\n",
       "      <td>0.479314</td>\n",
       "      <td>0.262283</td>\n",
       "      <td>0.109321</td>\n",
       "      <td>0.352495</td>\n",
       "      <td>0.179355</td>\n",
       "      <td>0.027973</td>\n",
       "      <td>0.342976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437479</td>\n",
       "      <td>0.086054</td>\n",
       "      <td>0.516020</td>\n",
       "      <td>0.268101</td>\n",
       "      <td>0.245675</td>\n",
       "      <td>0.068361</td>\n",
       "      <td>0.396083</td>\n",
       "      <td>0.339117</td>\n",
       "      <td>0.407547</td>\n",
       "      <td>0.549701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/233_83.jpg</th>\n",
       "      <td>0.347869</td>\n",
       "      <td>0.301712</td>\n",
       "      <td>0.522335</td>\n",
       "      <td>0.261258</td>\n",
       "      <td>0.116076</td>\n",
       "      <td>0.366591</td>\n",
       "      <td>0.154589</td>\n",
       "      <td>0.027978</td>\n",
       "      <td>0.339122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469073</td>\n",
       "      <td>0.068035</td>\n",
       "      <td>0.517897</td>\n",
       "      <td>0.313190</td>\n",
       "      <td>0.246146</td>\n",
       "      <td>0.068080</td>\n",
       "      <td>0.422717</td>\n",
       "      <td>0.336566</td>\n",
       "      <td>0.406794</td>\n",
       "      <td>0.583839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/234.jpg</th>\n",
       "      <td>0.347914</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.492523</td>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.103923</td>\n",
       "      <td>0.374593</td>\n",
       "      <td>0.194867</td>\n",
       "      <td>0.027595</td>\n",
       "      <td>0.341895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446093</td>\n",
       "      <td>0.074109</td>\n",
       "      <td>0.556251</td>\n",
       "      <td>0.276009</td>\n",
       "      <td>0.248838</td>\n",
       "      <td>0.075833</td>\n",
       "      <td>0.422568</td>\n",
       "      <td>0.340270</td>\n",
       "      <td>0.407056</td>\n",
       "      <td>0.564114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/234_100.jpg</th>\n",
       "      <td>0.347905</td>\n",
       "      <td>0.282819</td>\n",
       "      <td>0.565033</td>\n",
       "      <td>0.266834</td>\n",
       "      <td>0.093009</td>\n",
       "      <td>0.366808</td>\n",
       "      <td>0.203461</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>0.328456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456266</td>\n",
       "      <td>0.088293</td>\n",
       "      <td>0.544264</td>\n",
       "      <td>0.304154</td>\n",
       "      <td>0.319495</td>\n",
       "      <td>0.080180</td>\n",
       "      <td>0.356011</td>\n",
       "      <td>0.332229</td>\n",
       "      <td>0.407018</td>\n",
       "      <td>0.623976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/234_142.jpg</th>\n",
       "      <td>0.347850</td>\n",
       "      <td>0.308054</td>\n",
       "      <td>0.482397</td>\n",
       "      <td>0.260143</td>\n",
       "      <td>0.088492</td>\n",
       "      <td>0.400752</td>\n",
       "      <td>0.196235</td>\n",
       "      <td>0.028067</td>\n",
       "      <td>0.355385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434475</td>\n",
       "      <td>0.071690</td>\n",
       "      <td>0.551986</td>\n",
       "      <td>0.361602</td>\n",
       "      <td>0.261625</td>\n",
       "      <td>0.069161</td>\n",
       "      <td>0.361450</td>\n",
       "      <td>0.328213</td>\n",
       "      <td>0.407129</td>\n",
       "      <td>0.605667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/234_319.jpg</th>\n",
       "      <td>0.347894</td>\n",
       "      <td>0.298008</td>\n",
       "      <td>0.553219</td>\n",
       "      <td>0.263670</td>\n",
       "      <td>0.086599</td>\n",
       "      <td>0.381966</td>\n",
       "      <td>0.196616</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>0.339004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513464</td>\n",
       "      <td>0.076691</td>\n",
       "      <td>0.549992</td>\n",
       "      <td>0.290103</td>\n",
       "      <td>0.285822</td>\n",
       "      <td>0.075053</td>\n",
       "      <td>0.413943</td>\n",
       "      <td>0.330258</td>\n",
       "      <td>0.405934</td>\n",
       "      <td>0.580027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/235.jpg</th>\n",
       "      <td>0.347427</td>\n",
       "      <td>0.298323</td>\n",
       "      <td>0.464469</td>\n",
       "      <td>0.281841</td>\n",
       "      <td>0.178095</td>\n",
       "      <td>0.516194</td>\n",
       "      <td>0.140689</td>\n",
       "      <td>0.028022</td>\n",
       "      <td>0.381757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722325</td>\n",
       "      <td>0.069865</td>\n",
       "      <td>0.667726</td>\n",
       "      <td>0.325447</td>\n",
       "      <td>0.261422</td>\n",
       "      <td>0.056144</td>\n",
       "      <td>0.453937</td>\n",
       "      <td>0.344183</td>\n",
       "      <td>0.406482</td>\n",
       "      <td>0.521604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/235_149.jpg</th>\n",
       "      <td>0.347644</td>\n",
       "      <td>0.253301</td>\n",
       "      <td>0.531856</td>\n",
       "      <td>0.282262</td>\n",
       "      <td>0.163623</td>\n",
       "      <td>0.552402</td>\n",
       "      <td>0.170220</td>\n",
       "      <td>0.072789</td>\n",
       "      <td>0.363133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645324</td>\n",
       "      <td>0.077601</td>\n",
       "      <td>0.713967</td>\n",
       "      <td>0.322405</td>\n",
       "      <td>0.316857</td>\n",
       "      <td>0.058468</td>\n",
       "      <td>0.449768</td>\n",
       "      <td>0.342775</td>\n",
       "      <td>0.406405</td>\n",
       "      <td>0.524419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/235_328.jpg</th>\n",
       "      <td>0.347633</td>\n",
       "      <td>0.255121</td>\n",
       "      <td>0.504210</td>\n",
       "      <td>0.281003</td>\n",
       "      <td>0.165465</td>\n",
       "      <td>0.552085</td>\n",
       "      <td>0.178312</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>0.360034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629498</td>\n",
       "      <td>0.072677</td>\n",
       "      <td>0.732911</td>\n",
       "      <td>0.287755</td>\n",
       "      <td>0.326521</td>\n",
       "      <td>0.064370</td>\n",
       "      <td>0.449231</td>\n",
       "      <td>0.339441</td>\n",
       "      <td>0.406152</td>\n",
       "      <td>0.593785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/235_74.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.264462</td>\n",
       "      <td>0.513586</td>\n",
       "      <td>0.282878</td>\n",
       "      <td>0.170467</td>\n",
       "      <td>0.516904</td>\n",
       "      <td>0.155479</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>0.388520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612091</td>\n",
       "      <td>0.073353</td>\n",
       "      <td>0.695694</td>\n",
       "      <td>0.337337</td>\n",
       "      <td>0.248401</td>\n",
       "      <td>0.054362</td>\n",
       "      <td>0.424530</td>\n",
       "      <td>0.339210</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.581521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/236.jpg</th>\n",
       "      <td>0.347878</td>\n",
       "      <td>0.280637</td>\n",
       "      <td>0.406709</td>\n",
       "      <td>0.260801</td>\n",
       "      <td>0.100542</td>\n",
       "      <td>0.394828</td>\n",
       "      <td>0.146816</td>\n",
       "      <td>0.027961</td>\n",
       "      <td>0.339206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519069</td>\n",
       "      <td>0.069468</td>\n",
       "      <td>0.519798</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.246205</td>\n",
       "      <td>0.053808</td>\n",
       "      <td>0.411950</td>\n",
       "      <td>0.335718</td>\n",
       "      <td>0.406775</td>\n",
       "      <td>0.509664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/236_26.jpg</th>\n",
       "      <td>0.347514</td>\n",
       "      <td>0.267688</td>\n",
       "      <td>0.444541</td>\n",
       "      <td>0.270219</td>\n",
       "      <td>0.106029</td>\n",
       "      <td>0.390457</td>\n",
       "      <td>0.143542</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>0.359291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515889</td>\n",
       "      <td>0.069214</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.235176</td>\n",
       "      <td>0.245987</td>\n",
       "      <td>0.050925</td>\n",
       "      <td>0.410925</td>\n",
       "      <td>0.345015</td>\n",
       "      <td>0.406379</td>\n",
       "      <td>0.521184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/245_227.jpg</th>\n",
       "      <td>0.347956</td>\n",
       "      <td>0.274887</td>\n",
       "      <td>0.470149</td>\n",
       "      <td>0.279846</td>\n",
       "      <td>0.192947</td>\n",
       "      <td>0.421874</td>\n",
       "      <td>0.206939</td>\n",
       "      <td>0.038716</td>\n",
       "      <td>0.371698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561482</td>\n",
       "      <td>0.106857</td>\n",
       "      <td>0.575842</td>\n",
       "      <td>0.368457</td>\n",
       "      <td>0.312192</td>\n",
       "      <td>0.066263</td>\n",
       "      <td>0.404748</td>\n",
       "      <td>0.291598</td>\n",
       "      <td>0.407474</td>\n",
       "      <td>0.500560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/245_51.jpg</th>\n",
       "      <td>0.347702</td>\n",
       "      <td>0.301717</td>\n",
       "      <td>0.425224</td>\n",
       "      <td>0.282018</td>\n",
       "      <td>0.195801</td>\n",
       "      <td>0.436593</td>\n",
       "      <td>0.200659</td>\n",
       "      <td>0.076238</td>\n",
       "      <td>0.369230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580640</td>\n",
       "      <td>0.150989</td>\n",
       "      <td>0.564969</td>\n",
       "      <td>0.249138</td>\n",
       "      <td>0.300129</td>\n",
       "      <td>0.080539</td>\n",
       "      <td>0.462996</td>\n",
       "      <td>0.318537</td>\n",
       "      <td>0.406719</td>\n",
       "      <td>0.510504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/246.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.252022</td>\n",
       "      <td>0.413611</td>\n",
       "      <td>0.282303</td>\n",
       "      <td>0.184228</td>\n",
       "      <td>0.408445</td>\n",
       "      <td>0.210669</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>0.407080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.154002</td>\n",
       "      <td>0.613996</td>\n",
       "      <td>0.286285</td>\n",
       "      <td>0.253786</td>\n",
       "      <td>0.144248</td>\n",
       "      <td>0.395235</td>\n",
       "      <td>0.323316</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.513279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/246_189.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.284270</td>\n",
       "      <td>0.517324</td>\n",
       "      <td>0.281863</td>\n",
       "      <td>0.191257</td>\n",
       "      <td>0.486817</td>\n",
       "      <td>0.196489</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.395325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627469</td>\n",
       "      <td>0.164548</td>\n",
       "      <td>0.639215</td>\n",
       "      <td>0.263084</td>\n",
       "      <td>0.291011</td>\n",
       "      <td>0.149301</td>\n",
       "      <td>0.342659</td>\n",
       "      <td>0.312260</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.533760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/246_216.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.278474</td>\n",
       "      <td>0.516255</td>\n",
       "      <td>0.282250</td>\n",
       "      <td>0.170064</td>\n",
       "      <td>0.455103</td>\n",
       "      <td>0.211807</td>\n",
       "      <td>0.047859</td>\n",
       "      <td>0.387486</td>\n",
       "      <td>0.013370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628032</td>\n",
       "      <td>0.178588</td>\n",
       "      <td>0.623160</td>\n",
       "      <td>0.278646</td>\n",
       "      <td>0.324090</td>\n",
       "      <td>0.140215</td>\n",
       "      <td>0.378138</td>\n",
       "      <td>0.322913</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.537389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/246_331.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.320013</td>\n",
       "      <td>0.526330</td>\n",
       "      <td>0.282225</td>\n",
       "      <td>0.195009</td>\n",
       "      <td>0.464072</td>\n",
       "      <td>0.209523</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>0.406045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612984</td>\n",
       "      <td>0.162181</td>\n",
       "      <td>0.625755</td>\n",
       "      <td>0.275238</td>\n",
       "      <td>0.246465</td>\n",
       "      <td>0.148378</td>\n",
       "      <td>0.409139</td>\n",
       "      <td>0.337556</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.458713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/247.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.252567</td>\n",
       "      <td>0.435594</td>\n",
       "      <td>0.282289</td>\n",
       "      <td>0.125809</td>\n",
       "      <td>0.447538</td>\n",
       "      <td>0.130380</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>0.421995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714848</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>0.681397</td>\n",
       "      <td>0.316137</td>\n",
       "      <td>0.246465</td>\n",
       "      <td>0.044513</td>\n",
       "      <td>0.460932</td>\n",
       "      <td>0.346472</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.488016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/247_310.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.251875</td>\n",
       "      <td>0.418542</td>\n",
       "      <td>0.282029</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.470021</td>\n",
       "      <td>0.128738</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>0.405677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609186</td>\n",
       "      <td>0.071991</td>\n",
       "      <td>0.684036</td>\n",
       "      <td>0.325801</td>\n",
       "      <td>0.246465</td>\n",
       "      <td>0.044901</td>\n",
       "      <td>0.452256</td>\n",
       "      <td>0.344854</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.470566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/247_335.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.259696</td>\n",
       "      <td>0.443372</td>\n",
       "      <td>0.281830</td>\n",
       "      <td>0.128175</td>\n",
       "      <td>0.496095</td>\n",
       "      <td>0.125663</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>0.408245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653478</td>\n",
       "      <td>0.069703</td>\n",
       "      <td>0.666870</td>\n",
       "      <td>0.325575</td>\n",
       "      <td>0.246465</td>\n",
       "      <td>0.045891</td>\n",
       "      <td>0.446175</td>\n",
       "      <td>0.346947</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.475320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/247_345.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.230530</td>\n",
       "      <td>0.479754</td>\n",
       "      <td>0.282101</td>\n",
       "      <td>0.129186</td>\n",
       "      <td>0.462559</td>\n",
       "      <td>0.147493</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>0.415497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737211</td>\n",
       "      <td>0.067362</td>\n",
       "      <td>0.701300</td>\n",
       "      <td>0.332385</td>\n",
       "      <td>0.246465</td>\n",
       "      <td>0.045870</td>\n",
       "      <td>0.450205</td>\n",
       "      <td>0.346925</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.474317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/248.jpg</th>\n",
       "      <td>0.347748</td>\n",
       "      <td>0.296631</td>\n",
       "      <td>0.457982</td>\n",
       "      <td>0.282320</td>\n",
       "      <td>0.236408</td>\n",
       "      <td>0.520282</td>\n",
       "      <td>0.213339</td>\n",
       "      <td>0.065465</td>\n",
       "      <td>0.388136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621983</td>\n",
       "      <td>0.056763</td>\n",
       "      <td>0.727542</td>\n",
       "      <td>0.352771</td>\n",
       "      <td>0.351288</td>\n",
       "      <td>0.083804</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.406262</td>\n",
       "      <td>0.466477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/248_104.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.296941</td>\n",
       "      <td>0.463983</td>\n",
       "      <td>0.282069</td>\n",
       "      <td>0.234077</td>\n",
       "      <td>0.493948</td>\n",
       "      <td>0.204765</td>\n",
       "      <td>0.062485</td>\n",
       "      <td>0.368710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631778</td>\n",
       "      <td>0.068260</td>\n",
       "      <td>0.704599</td>\n",
       "      <td>0.344570</td>\n",
       "      <td>0.347292</td>\n",
       "      <td>0.081365</td>\n",
       "      <td>0.427393</td>\n",
       "      <td>0.365460</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.516500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/248_175.jpg</th>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.292972</td>\n",
       "      <td>0.513475</td>\n",
       "      <td>0.280776</td>\n",
       "      <td>0.234142</td>\n",
       "      <td>0.515777</td>\n",
       "      <td>0.203810</td>\n",
       "      <td>0.076026</td>\n",
       "      <td>0.372813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608275</td>\n",
       "      <td>0.178045</td>\n",
       "      <td>0.714272</td>\n",
       "      <td>0.380680</td>\n",
       "      <td>0.391122</td>\n",
       "      <td>0.081776</td>\n",
       "      <td>0.350306</td>\n",
       "      <td>0.316652</td>\n",
       "      <td>0.406067</td>\n",
       "      <td>0.507303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/248_7.jpg</th>\n",
       "      <td>0.347900</td>\n",
       "      <td>0.254246</td>\n",
       "      <td>0.506052</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.221076</td>\n",
       "      <td>0.522764</td>\n",
       "      <td>0.205630</td>\n",
       "      <td>0.061359</td>\n",
       "      <td>0.399067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699889</td>\n",
       "      <td>0.059951</td>\n",
       "      <td>0.674429</td>\n",
       "      <td>0.378078</td>\n",
       "      <td>0.317392</td>\n",
       "      <td>0.081769</td>\n",
       "      <td>0.366235</td>\n",
       "      <td>0.316765</td>\n",
       "      <td>0.406606</td>\n",
       "      <td>0.494878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/249.jpg</th>\n",
       "      <td>0.348163</td>\n",
       "      <td>0.341156</td>\n",
       "      <td>0.447405</td>\n",
       "      <td>0.258840</td>\n",
       "      <td>0.215697</td>\n",
       "      <td>0.391283</td>\n",
       "      <td>0.183203</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>0.351281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553459</td>\n",
       "      <td>0.155192</td>\n",
       "      <td>0.507959</td>\n",
       "      <td>0.272064</td>\n",
       "      <td>0.330639</td>\n",
       "      <td>0.125930</td>\n",
       "      <td>0.434304</td>\n",
       "      <td>0.345574</td>\n",
       "      <td>0.407440</td>\n",
       "      <td>0.497676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/249_132.jpg</th>\n",
       "      <td>0.347943</td>\n",
       "      <td>0.328260</td>\n",
       "      <td>0.479909</td>\n",
       "      <td>0.260115</td>\n",
       "      <td>0.213881</td>\n",
       "      <td>0.402077</td>\n",
       "      <td>0.207827</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>0.340597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498940</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.517889</td>\n",
       "      <td>0.350286</td>\n",
       "      <td>0.314153</td>\n",
       "      <td>0.123869</td>\n",
       "      <td>0.476516</td>\n",
       "      <td>0.349212</td>\n",
       "      <td>0.407178</td>\n",
       "      <td>0.534860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/249_153.jpg</th>\n",
       "      <td>0.347603</td>\n",
       "      <td>0.331681</td>\n",
       "      <td>0.492980</td>\n",
       "      <td>0.256405</td>\n",
       "      <td>0.228842</td>\n",
       "      <td>0.379733</td>\n",
       "      <td>0.184913</td>\n",
       "      <td>0.027976</td>\n",
       "      <td>0.347768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540344</td>\n",
       "      <td>0.130426</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.279579</td>\n",
       "      <td>0.278421</td>\n",
       "      <td>0.127023</td>\n",
       "      <td>0.510616</td>\n",
       "      <td>0.345789</td>\n",
       "      <td>0.407415</td>\n",
       "      <td>0.518759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/249_335.jpg</th>\n",
       "      <td>0.347929</td>\n",
       "      <td>0.340237</td>\n",
       "      <td>0.497678</td>\n",
       "      <td>0.254499</td>\n",
       "      <td>0.213551</td>\n",
       "      <td>0.406463</td>\n",
       "      <td>0.189296</td>\n",
       "      <td>0.028018</td>\n",
       "      <td>0.352781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497313</td>\n",
       "      <td>0.120246</td>\n",
       "      <td>0.521228</td>\n",
       "      <td>0.289391</td>\n",
       "      <td>0.330255</td>\n",
       "      <td>0.121810</td>\n",
       "      <td>0.465449</td>\n",
       "      <td>0.344790</td>\n",
       "      <td>0.407219</td>\n",
       "      <td>0.508235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/250.jpg</th>\n",
       "      <td>0.348676</td>\n",
       "      <td>0.232994</td>\n",
       "      <td>0.503763</td>\n",
       "      <td>0.288463</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.444318</td>\n",
       "      <td>0.141378</td>\n",
       "      <td>0.027418</td>\n",
       "      <td>0.344318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643205</td>\n",
       "      <td>0.089271</td>\n",
       "      <td>0.606159</td>\n",
       "      <td>0.286976</td>\n",
       "      <td>0.322391</td>\n",
       "      <td>0.063941</td>\n",
       "      <td>0.411476</td>\n",
       "      <td>0.337737</td>\n",
       "      <td>0.408638</td>\n",
       "      <td>0.483415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/250_118.jpg</th>\n",
       "      <td>0.348046</td>\n",
       "      <td>0.239991</td>\n",
       "      <td>0.506195</td>\n",
       "      <td>0.286672</td>\n",
       "      <td>0.111161</td>\n",
       "      <td>0.434034</td>\n",
       "      <td>0.144578</td>\n",
       "      <td>0.027527</td>\n",
       "      <td>0.343404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568851</td>\n",
       "      <td>0.052951</td>\n",
       "      <td>0.592329</td>\n",
       "      <td>0.303284</td>\n",
       "      <td>0.444139</td>\n",
       "      <td>0.062468</td>\n",
       "      <td>0.443967</td>\n",
       "      <td>0.311741</td>\n",
       "      <td>0.407297</td>\n",
       "      <td>0.462171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/250_323.jpg</th>\n",
       "      <td>0.347901</td>\n",
       "      <td>0.260176</td>\n",
       "      <td>0.471546</td>\n",
       "      <td>0.288395</td>\n",
       "      <td>0.110365</td>\n",
       "      <td>0.423060</td>\n",
       "      <td>0.144713</td>\n",
       "      <td>0.027714</td>\n",
       "      <td>0.337033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645361</td>\n",
       "      <td>0.057126</td>\n",
       "      <td>0.630429</td>\n",
       "      <td>0.294390</td>\n",
       "      <td>0.438595</td>\n",
       "      <td>0.064358</td>\n",
       "      <td>0.411546</td>\n",
       "      <td>0.337294</td>\n",
       "      <td>0.406654</td>\n",
       "      <td>0.437001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/250_331.jpg</th>\n",
       "      <td>0.348390</td>\n",
       "      <td>0.270845</td>\n",
       "      <td>0.475917</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.110279</td>\n",
       "      <td>0.438808</td>\n",
       "      <td>0.148925</td>\n",
       "      <td>0.027349</td>\n",
       "      <td>0.342674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624596</td>\n",
       "      <td>0.058999</td>\n",
       "      <td>0.560730</td>\n",
       "      <td>0.354825</td>\n",
       "      <td>0.287664</td>\n",
       "      <td>0.064914</td>\n",
       "      <td>0.417199</td>\n",
       "      <td>0.336849</td>\n",
       "      <td>0.407952</td>\n",
       "      <td>0.472483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/251.jpg</th>\n",
       "      <td>0.368859</td>\n",
       "      <td>0.299049</td>\n",
       "      <td>0.468118</td>\n",
       "      <td>0.366405</td>\n",
       "      <td>0.177368</td>\n",
       "      <td>0.469245</td>\n",
       "      <td>0.125322</td>\n",
       "      <td>0.075328</td>\n",
       "      <td>0.288751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664275</td>\n",
       "      <td>0.095451</td>\n",
       "      <td>0.525141</td>\n",
       "      <td>0.327688</td>\n",
       "      <td>0.280238</td>\n",
       "      <td>0.058677</td>\n",
       "      <td>0.451026</td>\n",
       "      <td>0.348930</td>\n",
       "      <td>0.445279</td>\n",
       "      <td>0.493301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/251_327.jpg</th>\n",
       "      <td>0.373545</td>\n",
       "      <td>0.284262</td>\n",
       "      <td>0.406347</td>\n",
       "      <td>0.351972</td>\n",
       "      <td>0.179669</td>\n",
       "      <td>0.422626</td>\n",
       "      <td>0.122849</td>\n",
       "      <td>0.068127</td>\n",
       "      <td>0.283051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629438</td>\n",
       "      <td>0.095066</td>\n",
       "      <td>0.554744</td>\n",
       "      <td>0.309611</td>\n",
       "      <td>0.227313</td>\n",
       "      <td>0.064418</td>\n",
       "      <td>0.466669</td>\n",
       "      <td>0.346292</td>\n",
       "      <td>0.437881</td>\n",
       "      <td>0.509096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/251_355.jpg</th>\n",
       "      <td>0.368977</td>\n",
       "      <td>0.293580</td>\n",
       "      <td>0.425543</td>\n",
       "      <td>0.364352</td>\n",
       "      <td>0.174412</td>\n",
       "      <td>0.446844</td>\n",
       "      <td>0.127969</td>\n",
       "      <td>0.077650</td>\n",
       "      <td>0.280992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625794</td>\n",
       "      <td>0.108777</td>\n",
       "      <td>0.540536</td>\n",
       "      <td>0.317425</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.060685</td>\n",
       "      <td>0.463439</td>\n",
       "      <td>0.351701</td>\n",
       "      <td>0.443935</td>\n",
       "      <td>0.479364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/251_48.jpg</th>\n",
       "      <td>0.372974</td>\n",
       "      <td>0.307169</td>\n",
       "      <td>0.423309</td>\n",
       "      <td>0.305468</td>\n",
       "      <td>0.172546</td>\n",
       "      <td>0.437290</td>\n",
       "      <td>0.127161</td>\n",
       "      <td>0.036221</td>\n",
       "      <td>0.291827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626061</td>\n",
       "      <td>0.081270</td>\n",
       "      <td>0.560434</td>\n",
       "      <td>0.287262</td>\n",
       "      <td>0.234170</td>\n",
       "      <td>0.048576</td>\n",
       "      <td>0.459962</td>\n",
       "      <td>0.344153</td>\n",
       "      <td>0.440644</td>\n",
       "      <td>0.498737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/252.jpg</th>\n",
       "      <td>0.366405</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.455883</td>\n",
       "      <td>0.330095</td>\n",
       "      <td>0.087177</td>\n",
       "      <td>0.465723</td>\n",
       "      <td>0.165343</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580570</td>\n",
       "      <td>0.085941</td>\n",
       "      <td>0.595661</td>\n",
       "      <td>0.368551</td>\n",
       "      <td>0.313552</td>\n",
       "      <td>0.066467</td>\n",
       "      <td>0.350533</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>0.438001</td>\n",
       "      <td>0.503338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/252_135.jpg</th>\n",
       "      <td>0.365848</td>\n",
       "      <td>0.275550</td>\n",
       "      <td>0.447087</td>\n",
       "      <td>0.287069</td>\n",
       "      <td>0.099567</td>\n",
       "      <td>0.427302</td>\n",
       "      <td>0.169174</td>\n",
       "      <td>0.045235</td>\n",
       "      <td>0.281441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548516</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.514844</td>\n",
       "      <td>0.292021</td>\n",
       "      <td>0.236511</td>\n",
       "      <td>0.058584</td>\n",
       "      <td>0.430280</td>\n",
       "      <td>0.342895</td>\n",
       "      <td>0.425551</td>\n",
       "      <td>0.544667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/252_68.jpg</th>\n",
       "      <td>0.366504</td>\n",
       "      <td>0.331797</td>\n",
       "      <td>0.469395</td>\n",
       "      <td>0.277206</td>\n",
       "      <td>0.085119</td>\n",
       "      <td>0.450325</td>\n",
       "      <td>0.176414</td>\n",
       "      <td>0.029451</td>\n",
       "      <td>0.322347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530998</td>\n",
       "      <td>0.128321</td>\n",
       "      <td>0.581882</td>\n",
       "      <td>0.350219</td>\n",
       "      <td>0.286335</td>\n",
       "      <td>0.087474</td>\n",
       "      <td>0.437585</td>\n",
       "      <td>0.350524</td>\n",
       "      <td>0.433670</td>\n",
       "      <td>0.511647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/252_75.jpg</th>\n",
       "      <td>0.365991</td>\n",
       "      <td>0.294844</td>\n",
       "      <td>0.448167</td>\n",
       "      <td>0.285588</td>\n",
       "      <td>0.085727</td>\n",
       "      <td>0.417477</td>\n",
       "      <td>0.172032</td>\n",
       "      <td>0.025762</td>\n",
       "      <td>0.299626</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531244</td>\n",
       "      <td>0.114675</td>\n",
       "      <td>0.554406</td>\n",
       "      <td>0.336077</td>\n",
       "      <td>0.345022</td>\n",
       "      <td>0.072474</td>\n",
       "      <td>0.434830</td>\n",
       "      <td>0.338910</td>\n",
       "      <td>0.433401</td>\n",
       "      <td>0.540510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1         2         3         4    \\\n",
       "images/229.jpg      0.347885  0.312121  0.426286  0.280628  0.266532   \n",
       "images/229_196.jpg  0.348042  0.282433  0.475093  0.278334  0.251386   \n",
       "images/229_262.jpg  0.347790  0.283312  0.440433  0.263835  0.254680   \n",
       "images/229_45.jpg   0.348421  0.282668  0.512960  0.261995  0.292136   \n",
       "images/230.jpg      0.348366  0.238829  0.436449  0.288226  0.140132   \n",
       "images/230_200.jpg  0.348400  0.251860  0.505937  0.284331  0.142422   \n",
       "images/230_287.jpg  0.348064  0.219773  0.458193  0.287645  0.133351   \n",
       "images/230_341.jpg  0.348314  0.247347  0.483573  0.287436  0.141763   \n",
       "images/231.jpg      0.348331  0.253640  0.535971  0.281920  0.195679   \n",
       "images/231_212.jpg  0.349236  0.224221  0.468002  0.285454  0.192864   \n",
       "images/231_56.jpg   0.349252  0.216469  0.462914  0.286893  0.218426   \n",
       "images/231_80.jpg   0.348276  0.258963  0.483181  0.289719  0.196923   \n",
       "images/232.jpg      0.348157  0.306357  0.500418  0.253922  0.240013   \n",
       "images/232_202.jpg  0.348049  0.295973  0.432724  0.265168  0.236663   \n",
       "images/232_251.jpg  0.348409  0.260203  0.580436  0.262466  0.169528   \n",
       "images/232_327.jpg  0.348160  0.308511  0.572415  0.252780  0.223937   \n",
       "images/233.jpg      0.347988  0.356146  0.458956  0.263893  0.106727   \n",
       "images/233_207.jpg  0.347542  0.345601  0.456286  0.263432  0.097399   \n",
       "images/233_337.jpg  0.348107  0.347041  0.479314  0.262283  0.109321   \n",
       "images/233_83.jpg   0.347869  0.301712  0.522335  0.261258  0.116076   \n",
       "images/234.jpg      0.347914  0.296400  0.492523  0.261225  0.103923   \n",
       "images/234_100.jpg  0.347905  0.282819  0.565033  0.266834  0.093009   \n",
       "images/234_142.jpg  0.347850  0.308054  0.482397  0.260143  0.088492   \n",
       "images/234_319.jpg  0.347894  0.298008  0.553219  0.263670  0.086599   \n",
       "images/235.jpg      0.347427  0.298323  0.464469  0.281841  0.178095   \n",
       "images/235_149.jpg  0.347644  0.253301  0.531856  0.282262  0.163623   \n",
       "images/235_328.jpg  0.347633  0.255121  0.504210  0.281003  0.165465   \n",
       "images/235_74.jpg   0.347602  0.264462  0.513586  0.282878  0.170467   \n",
       "images/236.jpg      0.347878  0.280637  0.406709  0.260801  0.100542   \n",
       "images/236_26.jpg   0.347514  0.267688  0.444541  0.270219  0.106029   \n",
       "...                      ...       ...       ...       ...       ...   \n",
       "images/245_227.jpg  0.347956  0.274887  0.470149  0.279846  0.192947   \n",
       "images/245_51.jpg   0.347702  0.301717  0.425224  0.282018  0.195801   \n",
       "images/246.jpg      0.347602  0.252022  0.413611  0.282303  0.184228   \n",
       "images/246_189.jpg  0.347602  0.284270  0.517324  0.281863  0.191257   \n",
       "images/246_216.jpg  0.347602  0.278474  0.516255  0.282250  0.170064   \n",
       "images/246_331.jpg  0.347602  0.320013  0.526330  0.282225  0.195009   \n",
       "images/247.jpg      0.347602  0.252567  0.435594  0.282289  0.125809   \n",
       "images/247_310.jpg  0.347602  0.251875  0.418542  0.282029  0.131148   \n",
       "images/247_335.jpg  0.347602  0.259696  0.443372  0.281830  0.128175   \n",
       "images/247_345.jpg  0.347602  0.230530  0.479754  0.282101  0.129186   \n",
       "images/248.jpg      0.347748  0.296631  0.457982  0.282320  0.236408   \n",
       "images/248_104.jpg  0.347602  0.296941  0.463983  0.282069  0.234077   \n",
       "images/248_175.jpg  0.347602  0.292972  0.513475  0.280776  0.234142   \n",
       "images/248_7.jpg    0.347900  0.254246  0.506052  0.282177  0.221076   \n",
       "images/249.jpg      0.348163  0.341156  0.447405  0.258840  0.215697   \n",
       "images/249_132.jpg  0.347943  0.328260  0.479909  0.260115  0.213881   \n",
       "images/249_153.jpg  0.347603  0.331681  0.492980  0.256405  0.228842   \n",
       "images/249_335.jpg  0.347929  0.340237  0.497678  0.254499  0.213551   \n",
       "images/250.jpg      0.348676  0.232994  0.503763  0.288463  0.116409   \n",
       "images/250_118.jpg  0.348046  0.239991  0.506195  0.286672  0.111161   \n",
       "images/250_323.jpg  0.347901  0.260176  0.471546  0.288395  0.110365   \n",
       "images/250_331.jpg  0.348390  0.270845  0.475917  0.290076  0.110279   \n",
       "images/251.jpg      0.368859  0.299049  0.468118  0.366405  0.177368   \n",
       "images/251_327.jpg  0.373545  0.284262  0.406347  0.351972  0.179669   \n",
       "images/251_355.jpg  0.368977  0.293580  0.425543  0.364352  0.174412   \n",
       "images/251_48.jpg   0.372974  0.307169  0.423309  0.305468  0.172546   \n",
       "images/252.jpg      0.366405  0.330472  0.455883  0.330095  0.087177   \n",
       "images/252_135.jpg  0.365848  0.275550  0.447087  0.287069  0.099567   \n",
       "images/252_68.jpg   0.366504  0.331797  0.469395  0.277206  0.085119   \n",
       "images/252_75.jpg   0.365991  0.294844  0.448167  0.285588  0.085727   \n",
       "\n",
       "                         5         6         7         8         9    \\\n",
       "images/229.jpg      0.417493  0.190636  0.028607  0.386184  0.000000   \n",
       "images/229_196.jpg  0.427501  0.168334  0.027984  0.368423  0.000000   \n",
       "images/229_262.jpg  0.433728  0.165925  0.027647  0.334038  0.000000   \n",
       "images/229_45.jpg   0.529770  0.146988  0.027779  0.344377  0.000000   \n",
       "images/230.jpg      0.453725  0.169919  0.027888  0.348023  0.000000   \n",
       "images/230_200.jpg  0.518545  0.162111  0.027354  0.348718  0.000000   \n",
       "images/230_287.jpg  0.488429  0.165254  0.027434  0.349248  0.000000   \n",
       "images/230_341.jpg  0.493413  0.161969  0.027340  0.343228  0.000000   \n",
       "images/231.jpg      0.519314  0.132833  0.027542  0.318920  0.000000   \n",
       "images/231_212.jpg  0.516859  0.129370  0.032095  0.333442  0.000000   \n",
       "images/231_56.jpg   0.514795  0.134831  0.027136  0.352922  0.000000   \n",
       "images/231_80.jpg   0.541549  0.120920  0.027658  0.336097  0.000000   \n",
       "images/232.jpg      0.392414  0.158380  0.027359  0.356790  0.000000   \n",
       "images/232_202.jpg  0.491952  0.142475  0.027718  0.338507  0.000000   \n",
       "images/232_251.jpg  0.448731  0.144055  0.081140  0.345482  0.000000   \n",
       "images/232_327.jpg  0.448215  0.144810  0.027983  0.352504  0.000000   \n",
       "images/233.jpg      0.361774  0.164111  0.027506  0.338696  0.000000   \n",
       "images/233_207.jpg  0.349786  0.182256  0.066705  0.344582  0.000000   \n",
       "images/233_337.jpg  0.352495  0.179355  0.027973  0.342976  0.000000   \n",
       "images/233_83.jpg   0.366591  0.154589  0.027978  0.339122  0.000000   \n",
       "images/234.jpg      0.374593  0.194867  0.027595  0.341895  0.000000   \n",
       "images/234_100.jpg  0.366808  0.203461  0.027857  0.328456  0.000000   \n",
       "images/234_142.jpg  0.400752  0.196235  0.028067  0.355385  0.000000   \n",
       "images/234_319.jpg  0.381966  0.196616  0.027857  0.339004  0.000000   \n",
       "images/235.jpg      0.516194  0.140689  0.028022  0.381757  0.000000   \n",
       "images/235_149.jpg  0.552402  0.170220  0.072789  0.363133  0.000000   \n",
       "images/235_328.jpg  0.552085  0.178312  0.028093  0.360034  0.000000   \n",
       "images/235_74.jpg   0.516904  0.155479  0.027848  0.388520  0.000000   \n",
       "images/236.jpg      0.394828  0.146816  0.027961  0.339206  0.000000   \n",
       "images/236_26.jpg   0.390457  0.143542  0.028093  0.359291  0.000000   \n",
       "...                      ...       ...       ...       ...       ...   \n",
       "images/245_227.jpg  0.421874  0.206939  0.038716  0.371698  0.000000   \n",
       "images/245_51.jpg   0.436593  0.200659  0.076238  0.369230  0.000000   \n",
       "images/246.jpg      0.408445  0.210669  0.028093  0.407080  0.000000   \n",
       "images/246_189.jpg  0.486817  0.196489  0.032258  0.395325  0.000000   \n",
       "images/246_216.jpg  0.455103  0.211807  0.047859  0.387486  0.013370   \n",
       "images/246_331.jpg  0.464072  0.209523  0.028093  0.406045  0.000000   \n",
       "images/247.jpg      0.447538  0.130380  0.028093  0.421995  0.000000   \n",
       "images/247_310.jpg  0.470021  0.128738  0.028093  0.405677  0.000000   \n",
       "images/247_335.jpg  0.496095  0.125663  0.028093  0.408245  0.000000   \n",
       "images/247_345.jpg  0.462559  0.147493  0.028093  0.415497  0.000000   \n",
       "images/248.jpg      0.520282  0.213339  0.065465  0.388136  0.000000   \n",
       "images/248_104.jpg  0.493948  0.204765  0.062485  0.368710  0.000000   \n",
       "images/248_175.jpg  0.515777  0.203810  0.076026  0.372813  0.000000   \n",
       "images/248_7.jpg    0.522764  0.205630  0.061359  0.399067  0.000000   \n",
       "images/249.jpg      0.391283  0.183203  0.027813  0.351281  0.000000   \n",
       "images/249_132.jpg  0.402077  0.207827  0.027634  0.340597  0.000000   \n",
       "images/249_153.jpg  0.379733  0.184913  0.027976  0.347768  0.000000   \n",
       "images/249_335.jpg  0.406463  0.189296  0.028018  0.352781  0.000000   \n",
       "images/250.jpg      0.444318  0.141378  0.027418  0.344318  0.000000   \n",
       "images/250_118.jpg  0.434034  0.144578  0.027527  0.343404  0.000000   \n",
       "images/250_323.jpg  0.423060  0.144713  0.027714  0.337033  0.000000   \n",
       "images/250_331.jpg  0.438808  0.148925  0.027349  0.342674  0.000000   \n",
       "images/251.jpg      0.469245  0.125322  0.075328  0.288751  0.000000   \n",
       "images/251_327.jpg  0.422626  0.122849  0.068127  0.283051  0.000000   \n",
       "images/251_355.jpg  0.446844  0.127969  0.077650  0.280992  0.000000   \n",
       "images/251_48.jpg   0.437290  0.127161  0.036221  0.291827  0.000000   \n",
       "images/252.jpg      0.465723  0.165343  0.059556  0.272574  0.000000   \n",
       "images/252_135.jpg  0.427302  0.169174  0.045235  0.281441  0.000000   \n",
       "images/252_68.jpg   0.450325  0.176414  0.029451  0.322347  0.000000   \n",
       "images/252_75.jpg   0.417477  0.172032  0.025762  0.299626  0.011497   \n",
       "\n",
       "                      ...          118       119       120       121  \\\n",
       "images/229.jpg        ...     0.633016  0.136140  0.585315  0.321328   \n",
       "images/229_196.jpg    ...     0.594656  0.143132  0.649892  0.295149   \n",
       "images/229_262.jpg    ...     0.564455  0.082824  0.627839  0.240245   \n",
       "images/229_45.jpg     ...     0.574621  0.125997  0.620627  0.300635   \n",
       "images/230.jpg        ...     0.622958  0.065635  0.623131  0.320368   \n",
       "images/230_200.jpg    ...     0.666371  0.102216  0.597925  0.271064   \n",
       "images/230_287.jpg    ...     0.598150  0.159060  0.622874  0.309921   \n",
       "images/230_341.jpg    ...     0.613823  0.065556  0.647031  0.252956   \n",
       "images/231.jpg        ...     0.591173  0.067689  0.611022  0.382788   \n",
       "images/231_212.jpg    ...     0.583231  0.072134  0.652523  0.309151   \n",
       "images/231_56.jpg     ...     0.611087  0.148659  0.630430  0.328203   \n",
       "images/231_80.jpg     ...     0.613038  0.085445  0.620990  0.310293   \n",
       "images/232.jpg        ...     0.606385  0.091465  0.505573  0.331711   \n",
       "images/232_202.jpg    ...     0.572823  0.059171  0.541217  0.342680   \n",
       "images/232_251.jpg    ...     0.561346  0.092905  0.535058  0.316981   \n",
       "images/232_327.jpg    ...     0.556294  0.096392  0.524904  0.305079   \n",
       "images/233.jpg        ...     0.450395  0.120138  0.519186  0.240653   \n",
       "images/233_207.jpg    ...     0.454468  0.065276  0.523580  0.249761   \n",
       "images/233_337.jpg    ...     0.437479  0.086054  0.516020  0.268101   \n",
       "images/233_83.jpg     ...     0.469073  0.068035  0.517897  0.313190   \n",
       "images/234.jpg        ...     0.446093  0.074109  0.556251  0.276009   \n",
       "images/234_100.jpg    ...     0.456266  0.088293  0.544264  0.304154   \n",
       "images/234_142.jpg    ...     0.434475  0.071690  0.551986  0.361602   \n",
       "images/234_319.jpg    ...     0.513464  0.076691  0.549992  0.290103   \n",
       "images/235.jpg        ...     0.722325  0.069865  0.667726  0.325447   \n",
       "images/235_149.jpg    ...     0.645324  0.077601  0.713967  0.322405   \n",
       "images/235_328.jpg    ...     0.629498  0.072677  0.732911  0.287755   \n",
       "images/235_74.jpg     ...     0.612091  0.073353  0.695694  0.337337   \n",
       "images/236.jpg        ...     0.519069  0.069468  0.519798  0.236097   \n",
       "images/236_26.jpg     ...     0.515889  0.069214  0.516700  0.235176   \n",
       "...                   ...          ...       ...       ...       ...   \n",
       "images/245_227.jpg    ...     0.561482  0.106857  0.575842  0.368457   \n",
       "images/245_51.jpg     ...     0.580640  0.150989  0.564969  0.249138   \n",
       "images/246.jpg        ...     0.676764  0.154002  0.613996  0.286285   \n",
       "images/246_189.jpg    ...     0.627469  0.164548  0.639215  0.263084   \n",
       "images/246_216.jpg    ...     0.628032  0.178588  0.623160  0.278646   \n",
       "images/246_331.jpg    ...     0.612984  0.162181  0.625755  0.275238   \n",
       "images/247.jpg        ...     0.714848  0.068667  0.681397  0.316137   \n",
       "images/247_310.jpg    ...     0.609186  0.071991  0.684036  0.325801   \n",
       "images/247_335.jpg    ...     0.653478  0.069703  0.666870  0.325575   \n",
       "images/247_345.jpg    ...     0.737211  0.067362  0.701300  0.332385   \n",
       "images/248.jpg        ...     0.621983  0.056763  0.727542  0.352771   \n",
       "images/248_104.jpg    ...     0.631778  0.068260  0.704599  0.344570   \n",
       "images/248_175.jpg    ...     0.608275  0.178045  0.714272  0.380680   \n",
       "images/248_7.jpg      ...     0.699889  0.059951  0.674429  0.378078   \n",
       "images/249.jpg        ...     0.553459  0.155192  0.507959  0.272064   \n",
       "images/249_132.jpg    ...     0.498940  0.106494  0.517889  0.350286   \n",
       "images/249_153.jpg    ...     0.540344  0.130426  0.523364  0.279579   \n",
       "images/249_335.jpg    ...     0.497313  0.120246  0.521228  0.289391   \n",
       "images/250.jpg        ...     0.643205  0.089271  0.606159  0.286976   \n",
       "images/250_118.jpg    ...     0.568851  0.052951  0.592329  0.303284   \n",
       "images/250_323.jpg    ...     0.645361  0.057126  0.630429  0.294390   \n",
       "images/250_331.jpg    ...     0.624596  0.058999  0.560730  0.354825   \n",
       "images/251.jpg        ...     0.664275  0.095451  0.525141  0.327688   \n",
       "images/251_327.jpg    ...     0.629438  0.095066  0.554744  0.309611   \n",
       "images/251_355.jpg    ...     0.625794  0.108777  0.540536  0.317425   \n",
       "images/251_48.jpg     ...     0.626061  0.081270  0.560434  0.287262   \n",
       "images/252.jpg        ...     0.580570  0.085941  0.595661  0.368551   \n",
       "images/252_135.jpg    ...     0.548516  0.073400  0.514844  0.292021   \n",
       "images/252_68.jpg     ...     0.530998  0.128321  0.581882  0.350219   \n",
       "images/252_75.jpg     ...     0.531244  0.114675  0.554406  0.336077   \n",
       "\n",
       "                         122       123       124       125       126       127  \n",
       "images/229.jpg      0.319590  0.071600  0.573633  0.325578  0.407397  0.489200  \n",
       "images/229_196.jpg  0.357228  0.102963  0.465853  0.345594  0.407546  0.555374  \n",
       "images/229_262.jpg  0.350610  0.073178  0.443575  0.345262  0.407321  0.571226  \n",
       "images/229_45.jpg   0.352492  0.097335  0.449535  0.352030  0.408274  0.481438  \n",
       "images/230.jpg      0.311093  0.100080  0.450236  0.336909  0.408458  0.457011  \n",
       "images/230_200.jpg  0.277888  0.107364  0.464044  0.368886  0.409705  0.464650  \n",
       "images/230_287.jpg  0.255302  0.144452  0.451410  0.366415  0.407984  0.491362  \n",
       "images/230_341.jpg  0.272582  0.097495  0.471553  0.342693  0.408179  0.510708  \n",
       "images/231.jpg      0.274460  0.080491  0.500623  0.340503  0.408043  0.550544  \n",
       "images/231_212.jpg  0.253360  0.073784  0.399554  0.346561  0.408868  0.545853  \n",
       "images/231_56.jpg   0.260759  0.124260  0.409085  0.346472  0.408932  0.645593  \n",
       "images/231_80.jpg   0.244655  0.081664  0.426819  0.357750  0.409168  0.557609  \n",
       "images/232.jpg      0.343670  0.098643  0.452735  0.341255  0.407176  0.484978  \n",
       "images/232_202.jpg  0.356843  0.067514  0.448504  0.343998  0.407555  0.504895  \n",
       "images/232_251.jpg  0.286806  0.069862  0.510644  0.328570  0.407334  0.469255  \n",
       "images/232_327.jpg  0.290308  0.072824  0.463550  0.340448  0.407462  0.505545  \n",
       "images/233.jpg      0.245660  0.067555  0.393944  0.349942  0.407554  0.539288  \n",
       "images/233_207.jpg  0.247186  0.069774  0.521025  0.328173  0.406886  0.551752  \n",
       "images/233_337.jpg  0.245675  0.068361  0.396083  0.339117  0.407547  0.549701  \n",
       "images/233_83.jpg   0.246146  0.068080  0.422717  0.336566  0.406794  0.583839  \n",
       "images/234.jpg      0.248838  0.075833  0.422568  0.340270  0.407056  0.564114  \n",
       "images/234_100.jpg  0.319495  0.080180  0.356011  0.332229  0.407018  0.623976  \n",
       "images/234_142.jpg  0.261625  0.069161  0.361450  0.328213  0.407129  0.605667  \n",
       "images/234_319.jpg  0.285822  0.075053  0.413943  0.330258  0.405934  0.580027  \n",
       "images/235.jpg      0.261422  0.056144  0.453937  0.344183  0.406482  0.521604  \n",
       "images/235_149.jpg  0.316857  0.058468  0.449768  0.342775  0.406405  0.524419  \n",
       "images/235_328.jpg  0.326521  0.064370  0.449231  0.339441  0.406152  0.593785  \n",
       "images/235_74.jpg   0.248401  0.054362  0.424530  0.339210  0.406067  0.581521  \n",
       "images/236.jpg      0.246205  0.053808  0.411950  0.335718  0.406775  0.509664  \n",
       "images/236_26.jpg   0.245987  0.050925  0.410925  0.345015  0.406379  0.521184  \n",
       "...                      ...       ...       ...       ...       ...       ...  \n",
       "images/245_227.jpg  0.312192  0.066263  0.404748  0.291598  0.407474  0.500560  \n",
       "images/245_51.jpg   0.300129  0.080539  0.462996  0.318537  0.406719  0.510504  \n",
       "images/246.jpg      0.253786  0.144248  0.395235  0.323316  0.406067  0.513279  \n",
       "images/246_189.jpg  0.291011  0.149301  0.342659  0.312260  0.406067  0.533760  \n",
       "images/246_216.jpg  0.324090  0.140215  0.378138  0.322913  0.406067  0.537389  \n",
       "images/246_331.jpg  0.246465  0.148378  0.409139  0.337556  0.406067  0.458713  \n",
       "images/247.jpg      0.246465  0.044513  0.460932  0.346472  0.406067  0.488016  \n",
       "images/247_310.jpg  0.246465  0.044901  0.452256  0.344854  0.406067  0.470566  \n",
       "images/247_335.jpg  0.246465  0.045891  0.446175  0.346947  0.406067  0.475320  \n",
       "images/247_345.jpg  0.246465  0.045870  0.450205  0.346925  0.406067  0.474317  \n",
       "images/248.jpg      0.351288  0.083804  0.356198  0.319444  0.406262  0.466477  \n",
       "images/248_104.jpg  0.347292  0.081365  0.427393  0.365460  0.406067  0.516500  \n",
       "images/248_175.jpg  0.391122  0.081776  0.350306  0.316652  0.406067  0.507303  \n",
       "images/248_7.jpg    0.317392  0.081769  0.366235  0.316765  0.406606  0.494878  \n",
       "images/249.jpg      0.330639  0.125930  0.434304  0.345574  0.407440  0.497676  \n",
       "images/249_132.jpg  0.314153  0.123869  0.476516  0.349212  0.407178  0.534860  \n",
       "images/249_153.jpg  0.278421  0.127023  0.510616  0.345789  0.407415  0.518759  \n",
       "images/249_335.jpg  0.330255  0.121810  0.465449  0.344790  0.407219  0.508235  \n",
       "images/250.jpg      0.322391  0.063941  0.411476  0.337737  0.408638  0.483415  \n",
       "images/250_118.jpg  0.444139  0.062468  0.443967  0.311741  0.407297  0.462171  \n",
       "images/250_323.jpg  0.438595  0.064358  0.411546  0.337294  0.406654  0.437001  \n",
       "images/250_331.jpg  0.287664  0.064914  0.417199  0.336849  0.407952  0.472483  \n",
       "images/251.jpg      0.280238  0.058677  0.451026  0.348930  0.445279  0.493301  \n",
       "images/251_327.jpg  0.227313  0.064418  0.466669  0.346292  0.437881  0.509096  \n",
       "images/251_355.jpg  0.226957  0.060685  0.463439  0.351701  0.443935  0.479364  \n",
       "images/251_48.jpg   0.234170  0.048576  0.459962  0.344153  0.440644  0.498737  \n",
       "images/252.jpg      0.313552  0.066467  0.350533  0.329630  0.438001  0.503338  \n",
       "images/252_135.jpg  0.236511  0.058584  0.430280  0.342895  0.425551  0.544667  \n",
       "images/252_68.jpg   0.286335  0.087474  0.437585  0.350524  0.433670  0.511647  \n",
       "images/252_75.jpg   0.345022  0.072474  0.434830  0.338910  0.433401  0.540510  \n",
       "\n",
       "[96 rows x 128 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(dict, orient='index')\n",
    "df\n",
    "#HOLY COW!  All of these are so close together. :-(  Can't differentiate one from another easily - Deeper network help?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/229.jpg\n"
     ]
    }
   ],
   "source": [
    "# Let's just view a few input images and output images\n",
    "\n",
    "#test_images=all_directory_images_generator()\n",
    "\n",
    "next_batch, next_filenames = next(test_images)\n",
    "#next_batch = next(test_generator)\n",
    "images = next_batch[0]\n",
    "first_image=images[0]\n",
    "second_image=images[1]\n",
    "\n",
    "plt.imshow(get_image(first_image))\n",
    "plt.show()\n",
    "\n",
    "#plt.imshow(second_image)\n",
    "#plt.show()\n",
    "\n",
    "recreated_pill = autoencoder.predict(x=images,batch_size=32)\n",
    "\n",
    "plt.imshow(get_image(recreated_pill[0]))\n",
    "plt.show()\n",
    "print(next_filenames[0])\n",
    "#categories = next_batch[1]\n",
    "#print(categories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# For confusion matrix, you need two items, y_test and y_pred\n",
    "#     y_test is the known categorical values of the test set \n",
    "#     y_pred is the predicted categorical values of the test set \n",
    "\n",
    "# To get y_test we'll use the validation_generator, but let's grab all images\n",
    "#test_generator.batch_size = 751\n",
    "\n",
    "nb_batches_to_capture = 1 # batches * batch_size should be less than total number of items available, else repeats will happen\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for index in range(nb_batches_to_capture):\n",
    "    next_batch = next(test_generator)\n",
    "    #images = next_batch[0]\n",
    "    #print(images[0])\n",
    "    categories = next_batch[1]\n",
    "    #print(categories[0])\n",
    "    #print(len(categories))\n",
    "    # To get y_pred, we actually need to predict the categories of the all_images set\n",
    "    #predicted_categories= model.predict_classes(x=images,batch_size=batch_size)\n",
    "    #print(len(predicted_categories))\n",
    "    #if len(categories) == len(predicted_categories):\n",
    "    #    y_true.extend(categories)\n",
    "    #    y_pred.extend(predicted_categories)\n",
    "    #else:\n",
    "    #    print(\"Mismatched actual and predicted - ignoring batch\")\n",
    "    \n",
    "print(len(y_true))\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create methods for determining closest image\n",
    "def retrieve_closest_elements(test_code, test_label, learned_codes):\n",
    "    distances = []\n",
    "    for code in learned_codes:\n",
    "        distance = np.linalg.norm(code - test_code)\n",
    "        distances.append(distance)\n",
    "    nb_elements = learned_codes.shape[0]\n",
    "    distances = np.array(distances)\n",
    "    learned_code_index = np.arange(nb_elements)\n",
    "    labels = np.copy(y_train).astype('float32')\n",
    "    labels[labels != test_label] = -1\n",
    "    labels[labels == test_label] = 1\n",
    "    labels[labels == -1] = 0\n",
    "    distance_with_labels = np.stack((distances, labels, learned_code_index), axis=-1)\n",
    "    sorted_distance_with_labels = distance_with_labels[distance_with_labels[:, 0].argsort()]\n",
    "\n",
    "    sorted_distances = 28 - sorted_distance_with_labels[:, 0]\n",
    "    sorted_labels = sorted_distance_with_labels[:, 1]\n",
    "    sorted_indexes = sorted_distance_with_labels[:, 2]\n",
    "    return sorted_distances, sorted_labels, sorted_indexes\n",
    "\n",
    "\n",
    "def compute_average_precision_score(test_codes, test_labels, learned_codes, n_samples):\n",
    "    out_labels = []\n",
    "    out_distances = []\n",
    "    retrieved_elements_indexes = []\n",
    "    for i in range(len(test_codes)):\n",
    "        sorted_distances, sorted_labels, sorted_indexes = retrieve_closest_elements(test_codes[i], test_labels[i], learned_codes)\n",
    "        out_distances.append(sorted_distances[:n_samples])\n",
    "        out_labels.append(sorted_labels[:n_samples])\n",
    "        retrieved_elements_indexes.append(sorted_indexes[:n_samples])\n",
    "\n",
    "    out_labels = np.array(out_labels)\n",
    "    out_labels_file_name = 'computed_data/out_labels_{}'.format(n_samples)\n",
    "    np.save(out_labels_file_name, out_labels)\n",
    "\n",
    "    out_distances_file_name = 'computed_data/out_distances_{}'.format(n_samples)\n",
    "    out_distances = np.array(out_distances)\n",
    "    np.save(out_distances_file_name, out_distances)\n",
    "    score = label_ranking_average_precision_score(out_labels, out_distances)\n",
    "    scores.append(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "def retrieve_closest_images(test_element, test_label, n_samples=10):\n",
    "    learned_codes = encoder.predict(x_train)\n",
    "    learned_codes = learned_codes.reshape(learned_codes.shape[0],\n",
    "                                          learned_codes.shape[1] * learned_codes.shape[2] * learned_codes.shape[3])\n",
    "\n",
    "    test_code = encoder.predict(np.array([test_element]))\n",
    "    test_code = test_code.reshape(test_code.shape[1] * test_code.shape[2] * test_code.shape[3])\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    for code in learned_codes:\n",
    "        distance = np.linalg.norm(code - test_code)\n",
    "        distances.append(distance)\n",
    "    nb_elements = learned_codes.shape[0]\n",
    "    distances = np.array(distances)\n",
    "    learned_code_index = np.arange(nb_elements)\n",
    "    labels = np.copy(y_train).astype('float32')\n",
    "    labels[labels != test_label] = -1\n",
    "    labels[labels == test_label] = 1\n",
    "    labels[labels == -1] = 0\n",
    "    distance_with_labels = np.stack((distances, labels, learned_code_index), axis=-1)\n",
    "    sorted_distance_with_labels = distance_with_labels[distance_with_labels[:, 0].argsort()]\n",
    "\n",
    "    sorted_distances = 28 - sorted_distance_with_labels[:, 0]\n",
    "    sorted_labels = sorted_distance_with_labels[:, 1]\n",
    "    sorted_indexes = sorted_distance_with_labels[:, 2]\n",
    "    kept_indexes = sorted_indexes[:n_samples]\n",
    "\n",
    "    score = label_ranking_average_precision_score(np.array([sorted_labels[:n_samples]]), np.array([sorted_distances[:n_samples]]))\n",
    "\n",
    "    print(\"Average precision ranking score for tested element is {}\".format(score))\n",
    "\n",
    "    original_image = x_test[0]\n",
    "    cv2.imshow('original_image', original_image)\n",
    "    retrieved_images = x_train[int(kept_indexes[0]), :]\n",
    "    for i in range(1, n_samples):\n",
    "        retrieved_images = np.hstack((retrieved_images, x_train[int(kept_indexes[i]), :]))\n",
    "    cv2.imshow('Results', retrieved_images)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    cv2.imwrite('test_results/original_image.jpg', 255 * cv2.resize(original_image, (0,0), fx=3, fy=3))\n",
    "    cv2.imwrite('test_results/retrieved_results.jpg', 255 * cv2.resize(retrieved_images, (0,0), fx=2, fy=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create methods to test the model\n",
    "def test_model(n_test_samples, n_train_samples):\n",
    "    learned_codes = encoder.predict(x_train)\n",
    "    learned_codes = learned_codes.reshape(learned_codes.shape[0], learned_codes.shape[1] * learned_codes.shape[2] * learned_codes.shape[3])\n",
    "    test_codes = encoder.predict(x_test)\n",
    "    test_codes = test_codes.reshape(test_codes.shape[0], test_codes.shape[1] * test_codes.shape[2] * test_codes.shape[3])\n",
    "    indexes = np.arange(len(y_test))\n",
    "    np.random.shuffle(indexes)\n",
    "    indexes = indexes[:n_test_samples]\n",
    "\n",
    "    print('Start computing score for {} train samples'.format(n_train_samples))\n",
    "    t1 = time.time()\n",
    "    score = compute_average_precision_score(test_codes[indexes], y_test[indexes], learned_codes, n_train_samples)\n",
    "    t2 = time.time()\n",
    "    print('Score computed in: ', t2-t1)\n",
    "    print('Model score:', score)\n",
    "\n",
    "\n",
    "def plot_denoised_images():\n",
    "    denoised_images = autoencoder.predict(x_test_noisy.reshape(x_test_noisy.shape[0], x_test_noisy.shape[1], x_test_noisy.shape[2], 1))\n",
    "    test_img = x_test_noisy[0]\n",
    "    resized_test_img = cv2.resize(test_img, (280, 280))\n",
    "    #cv2.imshow('input', resized_test_img)\n",
    "    #cv2.waitKey(0)\n",
    "    output = denoised_images[0]\n",
    "    resized_output = cv2.resize(output, (280, 280))\n",
    "    #cv2.imshow('output', resized_output)\n",
    "    #cv2.waitKey(0)\n",
    "    cv2.imwrite('test_results/noisy_image.jpg', 255 * resized_test_img)\n",
    "    cv2.imwrite('test_results/denoised_image.jpg', 255 * resized_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-1dee7e72a3b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_train_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_train_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-192-fe2232d72cf5>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(n_test_samples, n_train_samples)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create methods to test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlearned_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlearned_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearned_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearned_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearned_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlearned_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlearned_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# To test the whole model\n",
    "n_test_samples = 100\n",
    "#n_train_samples = [10, 50, 100, 200, 300, 400, 500, 750, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000,\n",
    "#                   20000, 30000, 40000, 50000, 60000]\n",
    "\n",
    "n_train_samples = [10]\n",
    "\n",
    "for n_train_sample in n_train_samples:\n",
    "    test_model(n_test_samples, n_train_sample)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "np.save('computed_data/scores', np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To retrieve closest image\n",
    "retrieve_closest_images(x_test[0], y_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# To plot a denoised image\n",
    "plot_denoised_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
